/*============================================================================
@file npa_scheduler.c

NPA Scheduled Requests

Copyright (c) 2009-2013 Qualcomm Technologies Incorporated.
All Rights Reserved.
QUALCOMM Proprietary/GTDR

$Header: //components/rel/core.adsp/2.2/power/npa/src/scheduler/npa_scheduler.c#2 $
============================================================================*/
#include "npa_scheduler_internal.h"
#include "npa_resource.h"
#include "npa_remote_rpm_protocol.h"
#include "limits.h"
#include "CoreThread.h"
#include "CoreProperty.h"
#include "timer.h"
#include "rcinit.h"
#include "sleep_npa_scheduler.h"

#ifdef WINSIM
#include "npa_offline.h"
#endif /* WINSIM */

/* NPA_SCHEDULER_SLEEP_LPR_SUPPORTED is defined in SConscript */
#ifdef NPA_SCHEDULER_SLEEP_LPR_SUPPORTED
int npa_sleep_lpr_supported = 1;
#else
int npa_sleep_lpr_supported = 0;
#endif

/* Parameters used for npa_scheduler_remove */
#define NPA_UPDATE_START_TIMES 1
#define NPA_DONT_UPDATE_START_TIMES 0
#define NPA_LOCK_LIST 1
#define NPA_DONT_LOCK_LIST 0
#define NPA_DO_COMPLETE_LIST 1
#define NPA_DONT_DO_COMPLETE_LIST 0

/**
 * @brief Adjustment calculation used for figuring runtime latency.
 * Limited to a max change (1920 =>100 usec) at any single time
 * to prevent unusually large bad values from corrupting the
 * adjustment (e.g. breakpoint debugging).  
 *  
 * delta: positive number of the amount of time needed to be 
 *        adjusted to the left.
 */ 
#define NPA_SCHEDULER_CALCULATE_ADJUST(delta) (MIN((delta),1920))

/**
 * Max total adjustment allowed.
 * Note - These should be much less than min_issue_sched_timeout and
 * min_reschedule_delta else system can get into a constant poking mode.
 */
uint32 NPA_SCHEDULER_MAX_TIMER_ADJUSTMENT = 96000;   /* 5 msec */
uint32 NPA_SCHEDULER_MAX_LATENCY_ADJUSTMENT = 96000; /* 5 msec */
uint32 NPA_SCHEDULER_MAX_LPR_ADJUSTMENT = 9600;      /* 500 usec */

/**  Set to !0 to not do any forks but still keep the LPR structure. */
int npa_no_forks_allowed = 0;

/** queue/link list of scheduled client requests */
npa_scheduler_control npa_scheduler;

/**
 * Resource list for the Sleep Forked requests.
 * Right now Transactions just ignore the resource list
 * (other than making sure there is a valid pointer).
 * This will need to be updated to a dynamic list
 * if Transactions ever starts using it.
 */
const char *npa_scheduler_transaction_resources[] = {""};

/**
 * npa_scheduler_lpr initialization resources need.  These must be
 * available before this LPR can be initialized.
 */
const char *npa_scheduler_lpr_init_resources[]
             = {NPA_SCHEDULER_SLEEP_LPR_RESOURCE_NAME,
                NPA_SCHEDULER_SLEEP_CORE_CPU_WAKEUP_RESOURCE_NAME};
#define NUM_NPA_SCHEDULER_LPR_INIT_RESOURCES \
        NPA_ARRAY_SIZE(npa_scheduler_lpr_init_resources)


#ifndef NPA_USES_CORE_PROPERTY
/* DEVCFG not defined so need to access config data directly */
extern const npa_scheduler_config npa_scheduler_config_data;
extern const char *npa_lpr_issuable_resource_names_data[];
extern const npa_resource_config npa_resource_overrides_data[];

#else
/* Define DEVCFG structure info for npa_config_data */
CorePropertyStructure npa_scheduler_config_data_property_struct[] =
{
  CORE_PROPERTY_STRUCTURE_ELEMENT(npa_scheduler_config, log_buffer_size),
  CORE_PROPERTY_STRUCTURE_ELEMENT(npa_scheduler_config, scheduled_queue_allocation.initial),
  CORE_PROPERTY_STRUCTURE_ELEMENT(npa_scheduler_config, scheduled_queue_allocation.subsequent),
  CORE_PROPERTY_STRUCTURE_ELEMENT(npa_scheduler_config, scheduled_request_allocation.initial),
  CORE_PROPERTY_STRUCTURE_ELEMENT(npa_scheduler_config, scheduled_request_allocation.subsequent),
  CORE_PROPERTY_STRUCTURE_ELEMENT(npa_scheduler_config, scheduled_request_workloop.num_events),
  CORE_PROPERTY_STRUCTURE_ELEMENT(npa_scheduler_config, scheduled_request_workloop.priority),
  CORE_PROPERTY_STRUCTURE_ELEMENT(npa_scheduler_config, min_issue_sched_timeout),
  CORE_PROPERTY_STRUCTURE_ELEMENT(npa_scheduler_config, sched_latency),
  CORE_PROPERTY_STRUCTURE_ELEMENT(npa_scheduler_config, min_reschedule_delta),
  CORE_PROPERTY_STRUCTURE_ELEMENT(npa_scheduler_config, fork_lookahead_delta),
  CORE_PROPERTY_STRUCTURE_ELEMENT(npa_scheduler_config, request_latency),
  CORE_PROPERTY_STRUCTURE_ELEMENT(npa_scheduler_config, fork_latency),
  CORE_PROPERTY_STRUCTURE_ELEMENT(npa_scheduler_config, notify_latency),
  CORE_PROPERTY_STRUCTURE_ELEMENT(npa_scheduler_config, sleep_wake_transition_latency),
  CORE_PROPERTY_STRUCTURE_ELEMENT(npa_scheduler_config, lpr_enter_latency),
  CORE_PROPERTY_STRUCTURE_ELEMENT(npa_scheduler_config, lpr_exit_latency),
  CORE_PROPERTY_STRUCTURE_ELEMENT(npa_scheduler_config, lpr_now_delta),
  CORE_PROPERTY_STRUCTURE_ELEMENT(npa_scheduler_config, auto_complete_delta),
  CORE_PROPERTY_STRUCTURE_ELEMENT(npa_scheduler_config, clk_baseline),
  {NULL, 0, 0} /* last entry */
};
#endif /* !NPA_USES_CORE_PROPERTY */

static npa_client_handle 
  npa_scheduler_remove (npa_client_handle client,
                        uint32 update_start_times,
                        uint32 lock_list);

static void npa_scheduler_sort_insert(npa_client_handle client,
                                      npa_scheduler_queue_struct *list_ptr,
                                      int update_start_times);

static void npa_run_scheduler_notifies(void);

static void npa_setup_next_timeout(void);

const char *npa_scheduled_client_state_name(npa_scheduled_client_state state);

/**
 * <!-- npa_scheduler_mark_resource_lpr_issuable -->
 *
 * @brief Mark a resource as lpr issuable
 *
 * This is a callback that is registered for every resource in the 
 * lpr_issuable list.  When the resource is created this callback 
 * is called to set the NPA_RESOURCE_LPR_ISSUBALE attribute.
 *
 * @param context Unused
 * @param event_type Unused
 * @param data Resource name
 * @param data_size size of resource name
 */
void npa_scheduler_mark_resource_lpr_issuable( void *context,
                                               unsigned int event_type,
                                               void *data,
                                               unsigned int data_size )
{
  npa_resource *resource;
  CORE_VERIFY_PTR( data );
  resource = npa_find_resource( (char *)data );
  CORE_VERIFY_PTR( resource );
  resource->definition->attributes |= NPA_RESOURCE_LPR_ISSUABLE;
}


/**
 * <!-- npa_scheduler_target_config -->
 *
 * @brief Get NPA Scheduler config data
 *
 * Get the configuation data used by NPA for Scheduler initialization.
 *  
 * If NPA_USES_CORE_PROPERTY is defined, then use Core's
 * GetProperty routines to get the data from the DEVCFG interface.
 *
 * If NPA_USES_CORE_PROPERTY is not defined, then the SCONSCRIPT
 * will have linked in the data directly into the NPA image so return
 * the data directly.
 *
 * @return Pointer to an npa_scheduler_config table
 */
static const npa_scheduler_config *npa_scheduler_target_config( void )
{
#ifdef NPA_USES_CORE_PROPERTY
  const npa_scheduler_config *config_data = NULL;
  static npa_scheduler_config final_data;
  int count;

  /* check to see if there is Target Specific config data */
  if ( CORE_PROPERTY_SUCCESS ==
        CoreProperty_GetPtr("/dev/power/npa/target/config",
                            "scheduler_config_data",
                            (const void **) &config_data))
  { /* have target specific data and it is valid  This trump all else */
    /* make sure we have a valid pointer */
    CORE_VERIFY_PTR(config_data);

    /* last entry should point to its self */
    CORE_VERIFY_PTR(config_data == config_data->table_end);
    ULOG_RT_PRINTF_1( npa.log,
          "npa_scheduler_config:"
          " Target Specific NPA Target Config structure found: 0x%08x",
          config_data );

    /* can pass back the original*/
    return config_data;
  }
  else
  { /* Don't have Target specific config so get general config data */
    /* check to see if there is a config table and
     * get the pointer if it exists.  base_config will have 
     * its old value if there is not a match.
     */
    CoreProperty_GetPtr("/dev/power/npa/config",
                        "scheduler_config_data",
                        (const void **) &config_data);

    /* make sure we have a valid pointer */
    CORE_VERIFY_PTR(config_data);

    /* last entry should point to its self */
    CORE_VERIFY_PTR(config_data == config_data->table_end);

    ULOG_RT_PRINTF_1( npa.log,
          "npa_scheduler_config:"
          " General NPA Target Config structure found: 0x%08x",
          config_data );

    /* copy across to a writable location */
    memcpy(&final_data, config_data, sizeof(final_data));

    /* check to see if there are any extra overwrites to this data
     * dictated by the Target code
     */
    count 
      = CoreProperty_UpdateStructure("/dev/power/npa/target/scheduler_config",
                                     npa_scheduler_config_data_property_struct,
                                     (void *) &final_data);

    if (count > 0 && count <= CORE_PROPERTY_NO_ERROR)
    { /* updated a property */
      ULOG_RT_PRINTF_1( npa_scheduler.log,
                        "npa_target_config: %d Individual NPA Target Config found",
                        count );
    }
  }

  final_data.table_end = &final_data; /* proper table termination */

  return &final_data;

#else
  /* DEVCFG not defined so return data directly */
    /* last entry should point to its self */
    CORE_VERIFY(&npa_scheduler_config_data 
                == npa_scheduler_config_data.table_end);
    return &npa_scheduler_config_data;
#endif
}


/**
 * <!-- npa_scheduler_setup_lpr_issuable_resources -->
 *
 * @brief Register resources to be marked as LPR issuable
 * 
 * @param issuable_names : Null terminated array of char pointers
 */
static void npa_scheduler_setup_lpr_issuable_resources(const char **issuable_names)
{
  while (*issuable_names != NULL)
  { /* There is a string in the array */
    ULOG_RT_PRINTF_1( npa_scheduler.log,
                      "Marking \"%s\" LPR issuable",
                      *issuable_names);
    /* Add the callback to mark this resource as lpr issuable once it 
       is created */
    npa_resource_available_cb( *issuable_names, 
                               npa_scheduler_mark_resource_lpr_issuable,
                               NULL );
    ++issuable_names;
  }
}


/**
 * <!-- npa_scheduler_lpr_issuable_config -->
 *
 * @brief Get NPA Scheduler lpr issuable table
 * 
 * Get the configuation data used by NPA for Scheduler on resources that
 * are LPR issuable.  It is a list of pointers to resources' names.
 * 
 * If NPA_USES_CORE_PROPERTY is defined, then use Core's
 * GetProperty routines to get the data from the DEVCFG interface searching
 * for the regular config data and then appending in the target specific values
 * if they exist.
 *
 * If NPA_USES_CORE_PROPERTY is not defined, then the SCONSCRIPT
 * will have linked in the data directly into the NPA image so return
 * the data directly.
 *
 * @param list_ptr : Pointer to a npa_list header
 */
static void npa_scheduler_lpr_issuable_config(void)
{
#ifdef NPA_USES_CORE_PROPERTY
  const char **issuable_names = NULL; /* Array of char *s */

  /* Get lpr_issuable_resource_names run time config data if exists */
  if(CORE_PROPERTY_SUCCESS ==
       CoreProperty_GetPtr("/dev/power/npa/config",
                           "lpr_issuable_resource_names",
                           (const void **) &issuable_names))
  { /* updated version */
    ULOG_RT_PRINTF_0( npa_scheduler.log,
        "npa_init_scheduler: NPA LPR Issuable Resource Names found" );

    /* add unique names to the list */
    npa_scheduler_setup_lpr_issuable_resources(issuable_names);
  }

  /* Append the target specific config data if it exists */
  if(CORE_PROPERTY_SUCCESS ==
       CoreProperty_GetPtr("/dev/power/npa/target/config",
                           "lpr_issuable_resource_names",
                           (const void **) &issuable_names))
  { /* updated version */
    ULOG_RT_PRINTF_0( npa_scheduler.log,
        "npa_init_scheduler: Additional NPA LPR Issuable Resource Names found" );

    /* add unique names to the list */
    npa_scheduler_setup_lpr_issuable_resources(issuable_names);
  }

#else
  /* add unique names to the list */
  npa_scheduler_setup_lpr_issuable_resources(npa_lpr_issuable_resource_names_data);
#endif
}


/**
 * <!-- npa_scheduler_action_type_name -->
 *
 * @brief returns text for action type
 *
 * @param type : npa_scheduler_action_type to decode
 *
 * @return pointer to string of name of the action type.
 */
static const char *npa_scheduler_action_type_name(npa_scheduler_action_type type)
{
  switch (type)
  {
    case NPA_SCHEDULED_ACTION_TIMEOUT:  /* Timeout event has occured */
      return("NPA_SCHEDULED_ACTION_TIMEOUT");
  
    case NPA_SCHEDULED_ACTION_TRIGGER:  /* Run scheduled events now */
      return("NPA_SCHEDULED_ACTION_TRIGGER");

    case NPA_SCHEDULER_ACTION_LPR_WAKEUP:  /* Run scheduled events now */
      return("NPA_SCHEDULER_ACTION_LPR_WAKEUP");
  
    default:
    return("NPA_SCHEDULED_ACTION_UNKNOWN");
  }
}


/**
 * <!-- npa_update_start_time -->
 *
 * @brief Update a linked list's start time in each client starting at given client going towards head of the list.
 *
 * Stop when reach a client whose time doesn't change or (if 
 * do_complete_list is set) the head of the list is reached.
 *
 * NOTE : Caller is responsible for locking the list prior to
 *        calling this function.
 *
 * @param client : Client with which to start
 * @param do_complete_list : 0 means stop when reach client whose start time
 *                           is the same.
 *                           1 means stop when reach head of list.
 */
static void npa_update_start_time(npa_client_handle client,
                                  int do_complete_list)
{
  npa_scheduler_data *request_ptr;
  uint64 end_time;
  uint64 start_time;

  /* update this client and all preceeding clients start times */
  while (NULL != client)
  {
    request_ptr = client->request_ptr;
    CORE_VERIFY_PTR(request_ptr);

    end_time = request_ptr->request_time; /* assume client is earliest */

    if(request_ptr->next
       && (end_time > request_ptr->next->request_ptr->start_time))
    { /* Next's end time is earlier */
      end_time = request_ptr->next->request_ptr->start_time;
    }

    /* calculate new start time */
    start_time = end_time - request_ptr->active_latency.wake;

    if (start_time != request_ptr->start_time)
    { /* new start time so keep updating */
      request_ptr->start_time = start_time;
    }
    else if (0 == do_complete_list)
    { /* no change so rest of list is fine and not forced to do whole list
       * so done
       */
      break;
    }
        
    /* point to previous client */
    client = request_ptr->prev;
  }
}


/**
 * <!-- npa_issue_implied_complete -->
 *
 * @brief Issue an implied complete
 *
 * Issues the code to handle an implied complete.
 * Note - It is the caller's responsibility to make sure this routine
 * is protected from competing with other functions issuing requests
 * from the NPA Scheduler thread.  This can either be done by it running
 * in the Sleep LPR, running in the NPA Scheduler workloop thread, or 
 * protecting with npa_scheduler.scheduler_work_lock.
 *
 * @param client : Handle of the client for the request.  
 *                 Client handles are the same as the address
 *                 of the npa_client structure.
 */
static void npa_issue_implied_complete(npa_client_handle client)
{ 
  npa_scheduler_data *request_ptr;
  npa_work_request pending_request; /* pending state for this request
                                     * that needs to be applied
                                     */
  CORE_VERIFY_PTR(request_ptr = client->request_ptr);

  ULOG_RT_PRINTF_4( npa.log, 
            "npa_scheduler_implied_complete"
            " (handle: 0x%08x)"
            " (client: \"%s\")"
            " (start time: 0x%016llx)",
            client,
            client->name,
            ULOG64_LOWWORD(request_ptr->start_time),
            ULOG64_HIGHWORD(request_ptr->start_time));

  request_ptr->implied_state = NPA_IMPLIED_COMPLETE_IN_PROGRESS;
    
  /* save the pending request because we are about to
   * issue one on top of it.
   */
  memcpy(&pending_request, &(NPA_PENDING_REQUEST(client)),
         sizeof(pending_request));

  request_ptr->stats.last_implied_complete_time = CoreTimetick_Get64();

  npa_terminate_request( client );

  ++npa_scheduler.stats.implied_completes;

  /* restore the pending request */
  memcpy(&(NPA_PENDING_REQUEST(client)), &pending_request,
         sizeof(pending_request));
  
  /* since we issued the complete, anything that follows will assume 
    * to be a new request.
    */
  request_ptr->new_request = 1;

  /* The complete has now executed and if we just do a notify at this
   * point, say what has been done.
   */
  request_ptr->implied_state = NPA_IMPLIED_COMPLETE_EXECUTED;
  request_ptr->notify_state = NPA_SCHEDULED_NOTIFICATION_IMPLIED_COMPLETE_ISSUED;
 
  /* wake work is now the entire issue request again */
  request_ptr->active_latency.wake 
    = request_ptr->active_latency.request
      + request_ptr->active_latency.request_adjustment
      + request_ptr->active_latency.notify;

  /* Need to adjust the timeline from this client to first gap 
   * NOTE must lock the list first
   */
  if (request_ptr->my_queue && request_ptr->my_queue->lock)
  { /* in a queue so lock it */
    Core_MutexLock(request_ptr->my_queue->lock);
  }
  npa_update_start_time(client, NPA_DONT_DO_COMPLETE_LIST);
  if (request_ptr->my_queue && request_ptr->my_queue->lock)
  { /* in a queue so unlock it */
    Core_MutexUnlock(request_ptr->my_queue->lock);
  }
}


/**
 * <!-- npa_run_scheduler_request -->
 *
 * @brief Run specific request
 *
 * Runs the scheduled request for a specific client.
 *
 * npa_run_scheduler_notify() should be called this after all
 * client locks have been turned off.
 *
 *  @param client : Handle of the client for the request.  
 *                 Client handles are the same as the address
 *                 of the npa_client structure.
 *
 * @param dur_ptr : Pointer of area to update with duration
 *                  values.
 */
static void npa_run_scheduler_request(npa_client_handle client,
                                      npa_duration *dur_ptr)
{
  npa_scheduler_data *request_ptr = NULL;
  uint64 issue_dur = 0;
  uint64 start_time;
  uint64 expected_duration = 0;

  request_ptr = client->request_ptr;

  request_ptr->state = NPA_SCHEDULED_CLIENT_IN_PROGRESS;

  if ( NPA_IMPLIED_COMPLETE_PENDING == request_ptr->implied_state)
  { /* Need to remove from Implied complete list */
    npa_list_Remove( &npa_scheduler.implied_completes_now_list, client );
  }

  /* There is no implied complete needed now because beyond point
   * of ever backing out
   */
  request_ptr->implied_state = NPA_NO_IMPLIED_COMPLETE;

  /* put it in the request so no dangling pointer to
   * scheduler routines and in case other routines use 
   * this field.
   */
  client->issue_request = request_ptr->issue_request;
  request_ptr->issue_request = NULL; /* no danglers */

  if (request_ptr->new_request)
  { /* new request so run it */
    request_ptr->stats.last_issue_request_time
      = start_time = CoreTimetick_Get64();

    /* run the request */
    client->issue_request(client, request_ptr->new_request);

    issue_dur = npa_calc_duration(start_time, 
                                  CoreTimetick_Get64(),
                                  dur_ptr);

    /* expected duration is request latency plus last adjustment */
    expected_duration = request_ptr->active_latency.request
                        + request_ptr->active_latency.request_adjustment;

    /* Check to see if the duration was bigger than expected */
    if (issue_dur > expected_duration)
    { /* duration is bigger than expected so calculate 
       * an adjustment for next time. It doesn't matter if this a
       * regular request or LPR NAS, just want the biggest time
       * seen for calcalculating the backoff next time.  Regular
       * request should always be biggest times anyways.
       */
      request_ptr->active_latency.request_adjustment 
        = (uint32) 
            MIN(request_ptr->active_latency.request_adjustment 
                 + (uint32) NPA_SCHEDULER_CALCULATE_ADJUST(issue_dur-expected_duration),
                NPA_SCHEDULER_MAX_LATENCY_ADJUSTMENT);
    }
  }

  /* let the main log see when we run the request */
  ULOG_RT_PRINTF_5( npa_scheduler.log,
                    "\tnpa_run_scheduler_request"
                    " (handle: 0x%08x)"
                    " (issue_dur: %u)"
                    " (expected_duration: %u)"
                    " (adjustment: %u)"
                    " (new_request: %d)",
                    client, 
                    (uint32)issue_dur,
                    (uint32)expected_duration,
                    (uint32)request_ptr->active_latency.request_adjustment,
                    request_ptr->new_request
                  );
}


/**
 * <!-- npa_scheduler_notify -->
 *
 * @brief Handle the notify callback
 *
 * Clean up the client request data structures and then 
 * notify the client.  Must be called after the requests
 * has been handled.  If a lock is passed, it must be
 * "locked".
 *
 * @param client : Client to use for notification
 * @param lockptr : If not NULL, Lock to toggle off and then on.
 */
static void npa_scheduler_notify(npa_client_handle client,
                                 CoreMutex* lockptr)
{
  npa_scheduler_data *request_ptr;
  npa_scheduler_callback notify_ptr;
  npa_scheduled_notification_state notify_state;
  void *context;
  uint64 current_time;
  int64 delta;
  uint64 request_time;

  request_ptr = client->request_ptr;

  /* remember whom we need to notify */
  notify_ptr = request_ptr->notification;

  /* remember context */
  context = request_ptr->context;

  /* no dangling pointers but haven't called notification yet. */
  request_ptr->issue_request = NULL;
  request_ptr->notification = NULL;

  /* we are done with this request */
  request_ptr->state = NPA_SCHEDULED_CLIENT_INACTIVE;
  request_ptr->implied_state = NPA_NO_IMPLIED_COMPLETE;

  /* remember the request time because it could change before
   * the logging is printed out at the bottom.
   */
  request_time = request_ptr->request_time;

  /* update if request is done in time */
  request_ptr->stats.last_notificaiton_time
    = current_time = CoreTimetick_Get64();
  delta = npa_compare_times(request_ptr->request_time,current_time);
  if (0 <= delta
      || (0 == NPA_ACTIVE_REQUEST( client ).state))
  { /* current time is < request time or it
     * is a cancel/complete that is suppose to happen
     * after the request time so "on time"
     */
    notify_state = NPA_SCHEDULED_NOTIFICATION_ON_TIME;
    ++request_ptr->stats.on_time;
    ++npa_scheduler.stats.on_time;
  }
  else
  { /* current time is > requested time so late */
    notify_state = NPA_SCHEDULED_NOTIFICATION_LATE;
    delta = -delta; /* invert sign */
    ++request_ptr->stats.late;
    ++npa_scheduler.stats.late;
    request_ptr->stats.late_by_sum
      += current_time - request_ptr->request_time;
  }

  request_ptr->notify_state = notify_state;

  if (NULL != notify_ptr)
  { /* valid notification function so call it */
    /* remember the time for duration */
    current_time = CoreTimetick_Get64();
    request_ptr->stats.last_notificaiton_time = current_time;
    if (NULL != lockptr)
    { /* Have a lock we need to toggle */
      Core_MutexUnlock(lockptr);
      notify_ptr(client, request_ptr->notify_state, context);
      Core_MutexLock(lockptr);
    }
    else
    { /* No lock to toggle */
      notify_ptr(client, request_ptr->notify_state, context);
    }
    /* remember duration */
    npa_calc_duration(current_time, 
                      CoreTimetick_Get64(),
                      &request_ptr->stats.notify_issue_request_duration);

    /* remember the time we did a notification */
    request_ptr->stats.last_notification_time = current_time;

    ULOG_RT_PRINTF_9( npa_scheduler.log,
                      "  DONE npa_scheduler_notify:"
                      " (handle: 0x%08x)"
                      " (client: \"%s\")"
                      " (notify: 0x%08x)"
                      " (request_time: 0x%016llx)"
                      " (active request: %d)"
                      " (\"%s\")"
                      " (delta: %lld)",
                      client,
                      client->name,
                      notify_ptr,
                      ULOG64_LOWWORD(request_time),
                      ULOG64_HIGHWORD(request_time),
                      NPA_ACTIVE_REQUEST( client ).state,
                      npa_scheduler_status_name(notify_state),
                      ULOG64_LOWWORD(delta),
                      ULOG64_HIGHWORD(delta));
  }
}


/**
 * <!-- npa_run_scheduler_requests -->
 *
 * @brief Run pending requests
 *
 * Takes the current pending sorted scheduled request list and runs
 * the requests quest starting at the head.  It will run until the list
 * is either empty or a request is npa_max_reschedule_delta in the future.
 *
 * It will calculate a new timeout and setup another timer
 * when it has reached either point.
 *
 * @param action : Information about signal causing the function to be called
 */
void npa_run_scheduler_requests(npa_scheduler_action *action)
{
  uint64 start_time = CoreTimetick_Get64();
  uint64 func_duration;
  npa_client_handle client = NULL;
  npa_scheduler_data *request_ptr = NULL;
  int64 late_by;
  const char *adjective;

  uint64 max_handle_time;
  uint64 last_request_time;

  /* prevent pokes or timout setup since scheduler is active */
  npa_scheduler.next_timeout_state = NPA_SCHEDULER_NTS_NO_SETUP;

  /* Set CPU clock to max */
  if( npa_scheduler.clk_cpu_client)
  { /* client exists so can make max requests to the clock */
    npa_issue_suppressible_request( npa_scheduler.clk_cpu_client,
                                    npa_scheduler.config_ptr->clk_baseline);
  }

  /* remember time started */
  npa_scheduler.stats.last_run_scheduler_request_time = start_time;

  if ((NPA_SCHEDULED_ACTION_TIMEOUT == action->type
       || NPA_SCHEDULER_ACTION_LPR_WAKEUP == action->type))
  { /* expecting a timeout or LPR Wakeup and got it */

    /* time lag between now and when the timer fired */
    npa_calc_duration(npa_scheduler.timer.timedout_at,
                      start_time,
                      &npa_scheduler.stats.timeout_to_scheduler_duration);
  
    /* how "on time" we are? */
    late_by 
      = npa_compare_times(start_time,npa_scheduler.next_scheduler_time);  

    if (late_by > 0)
    { /* we are late so count it */
      uint64 adjust;
      npa_calc_duration(npa_scheduler.next_scheduler_time,
                        start_time,
                        &npa_scheduler.stats.run_requests_late_duration);
      adjective = "LATE";
  
      /* Want to calculate an adjustment for the next timeout/wakeup
       * event but want to limit it in case there is one bad large
       * value 
       */ 
      adjust = NPA_SCHEDULER_CALCULATE_ADJUST(late_by);

      if (NPA_SCHEDULED_ACTION_TIMEOUT == action->type)
      { /* Timer notification was late */
        npa_scheduler.adjust.timer
          = MIN(npa_scheduler.adjust.timer + adjust,
                NPA_SCHEDULER_MAX_TIMER_ADJUSTMENT);
      }
      else if (NPA_SCHEDULER_ACTION_LPR_WAKEUP == action->type)
      { /* LPR's notificaiton was late */
        npa_scheduler.adjust.lpr
          = MIN(npa_scheduler.adjust.lpr + adjust,
                NPA_SCHEDULER_MAX_LPR_ADJUSTMENT);
      }
    }
    else 
    { /* event is early */

      /* get absolute value for printout */
      late_by = ABS(late_by);

      if (late_by > npa_scheduler.config_ptr->auto_complete_delta)
      { /* running very early */
        npa_calc_duration(start_time,
                          npa_scheduler.next_scheduler_time,
                          &npa_scheduler.stats.run_requests_very_early_duration);
        adjective = "VERY EARLY";
      }
      else
      { /* just ahead of on time */
        npa_calc_duration(start_time,
                          npa_scheduler.next_scheduler_time,
                          &npa_scheduler.stats.run_requests_early_duration);
        adjective = "EARLY";
      }
    }
  }
  else
  { /* probably a poke so not late */
    late_by = 0;
    adjective = "";
  }

  ULOG_RT_PRINTF_9( npa_scheduler.log,
                  "START npa_run_scheduler_requests %d"
                  " (action type: 0x%08x - \"%s\")"
                  " (start vs. desired: \"%s\" %d)"
                  " (timedout_at: 0x%016llx)"
                  " (req head: 0x%08x)"
                  " (fork head: 0x%08x)", 
                  npa_scheduler.stats.num_run_scheduler_requests,
                  action->type,
                  npa_scheduler_action_type_name(action->type),
                  adjective,
                  (uint32) late_by,
                  ULOG64_LOWWORD(npa_scheduler.timer.timedout_at),
                  ULOG64_HIGHWORD(npa_scheduler.timer.timedout_at),
                  npa_scheduler.request_queue.head,
                  npa_scheduler.forked_queue.head);

#ifndef WINSIM /* WINSIM plays with this bit too much to trust it in sim */
  /* must not be in sleep */
  CORE_VERIFY(npa_scheduler.sleep.enter == 0);
#endif

  /* Any notifies pending */
  npa_run_scheduler_notifies();

  /* There is a narrow window that is open below if a client is destroyed
   * in the middle of removing it off the list and locking it.  Since
   * we don't want to block other clients from doing list work while
   * a request is being processed, we might want a specific lock for
   * destroying any client, but since this should be a very rare condition,
   * it is ok to have it locked for a long time.  
   */
  Core_MutexLock(npa_scheduler.scheduler_work_lock);

//  ULOG_RT_PRINTF_0( npa_scheduler.log,
//                    "  npa_run_scheduler_requests scheduler_work Locked");

  /* Mark the last request time as the current time so
   * it has something in a reasonable range
   */
  last_request_time = CoreTimetick_Get64();

  for ((client = npa_scheduler_remove(npa_scheduler.request_queue.head,
                                        NPA_DONT_UPDATE_START_TIMES,
                                        NPA_LOCK_LIST));
        NULL != client;
        (client = npa_scheduler_remove(npa_scheduler.request_queue.head,
                                        NPA_DONT_UPDATE_START_TIMES,
                                        NPA_LOCK_LIST))
       )
  { /* Now have first element in list.  If it was not in 
     * LINKED, npa_scheduler_remove would have returned NULL
     * so it must be in expected state.
     */
    if (NULL != client->request_ptr)
    { /* should always get here */

      request_ptr = client->request_ptr;
      
      /* there is a race condition where we removed it from
       * the list but the client came in and unscheduled it
       * before the client lock was applied.
       * Make sure still in UNLINKED state.
       */
      if (NPA_SCHEDULED_CLIENT_UNLINKED == request_ptr->state)
      { /* it is ours to use */

        /* The maximum handle time is the current time plus the deltas */ 
        max_handle_time = CoreTimetick_Get64() 
                          + npa_scheduler.config_ptr->min_reschedule_delta
                          + npa_scheduler.config_ptr->sched_latency
                          + npa_scheduler.adjust.timer;

        /* If it is too early, put back in list,
         * else execute.
         */
        if ((request_ptr->start_time > max_handle_time)
            && (request_ptr->request_time != last_request_time))
        { /* too far in the future and doesn't match last request time so reschedule */
          npa_scheduler_sort_insert(client, 
                                    &npa_scheduler.request_queue,
                                    NPA_UPDATE_START_TIMES);
//          ULOG_RT_PRINTF_7( npa_scheduler.log,
//                            "  No more to run"
//                            " (client: 0x%08x)"
//                            " (request_start_time: 0x%016llx)"
//                            " (max_handle_time: 0x%016llx)"
//                            " (last_request_time: 0x%016llx)",
//                            client,
//                            ULOG64_LOWWORD(request_ptr->start_time),
//                            ULOG64_HIGHWORD(request_ptr->start_time),
//                            ULOG64_LOWWORD(max_handle_time),
//                            ULOG64_HIGHWORD(max_handle_time),
//                            ULOG64_LOWWORD(last_request_time),
//                            ULOG64_HIGHWORD(last_request_time));

         break; /* done for this series as everything else on the list
                  * needs to run later.
                  */
        }
        else
        { /* handle request */
          ++npa_scheduler.stats.sched_requests_handled;

          /* remember this one's time for next compare */
          last_request_time = request_ptr->request_time;

          /* run the request.
           * this call will clear out request_ptr->notification.
           */
          npa_run_scheduler_request(client,
                                    &client->request_ptr->stats.full_issue_request_duration);

          /* issue notification inside the lock.
           */
          npa_scheduler_notify(client, NULL);
        }
      }
    }
    else
    { /* should never get here as request_ptr should always be defined.
       * But if we do, record and Core (but in a way that we could jump
       * over if needed)
       */
      ULOG_RT_PRINTF_1( npa_scheduler.log,
        "npa_run_scheduler_requests request_ptr == NULL "
        "(handle: 0x%08x)",
        client);
      CORE_VERIFY(0);
    }
  } /* while (client...) */


  if (npa_scheduler.complete_queue.head)
  {
    ULOG_RT_PRINTF_3( npa_scheduler.log,
                      "\tnpa_run_scheduler_requests Check Complete Queue"
                      " (handle: 0x%08x)"
                      " (start_time: 0x%016llx)",
                      npa_scheduler.complete_queue.head,
                      ULOG64_LOWWORD(npa_scheduler.complete_queue.head->request_ptr->start_time),
                      ULOG64_HIGHWORD(npa_scheduler.complete_queue.head->request_ptr->start_time));

    /* Check Complete Queue 
     * TODO - If there are many completes to handle, it may start eating
     * into the period needed for the request_queue.  Need some way to 
     * recheck if a request queue request needs to fire.
     */
    for ((client = npa_scheduler_remove(npa_scheduler.complete_queue.head,
                                          NPA_DONT_UPDATE_START_TIMES,
                                          NPA_LOCK_LIST));
          NULL != client;
          (client = npa_scheduler_remove(npa_scheduler.complete_queue.head,
                                          NPA_DONT_UPDATE_START_TIMES,
                                          NPA_LOCK_LIST))
         )
    {
      request_ptr = client->request_ptr;
      if (CoreTimetick_Get64() >= request_ptr->request_time)
      { /* Current time is after the start time so OK to run */
        /* run the request. */
        npa_run_scheduler_request(client,
                                  &request_ptr->stats.full_issue_request_duration);

        /* issue notification inside the lock. */
        npa_scheduler_notify(client, NULL);
      }
      else
      { /* to early so put back on list
         * Don't need to update start times, just need it to be
         * ordered.
         */
        npa_scheduler_sort_insert(client, 
                                  &npa_scheduler.complete_queue,
                                  NPA_DONT_UPDATE_START_TIMES);
        /* Insert overwrites the start time so put back to legal value */
        request_ptr->start_time = request_ptr->request_time;
        break;  /* done with the list */
      }
    }
  }
  
  /* if blocking timer, then release it.  Should only be 0 or 1 */
  if (npa_scheduler.timer.deferred_match_count)
  {
    CORE_LOG_VERIFY(0 == (--npa_scheduler.timer.deferred_match_count),
                    ULOG_RT_PRINTF_1( npa_scheduler.log, 
                                      "ERROR npa_run_scheduler_requests"
                                      " deferred_match_count %d"
                                      " is out of range",
                                      npa_scheduler.timer.deferred_match_count )
                    );

    timer_undefer_match_interrupt();
  }

  /* scheduler can be poked again and timeouts setup, 
   * including by the following npa_setup_next_timeout()
   * so no race condition exists.  Worst case is one
   * unneeded poke occurs for a very small race window compared
   * to blocking a lot of outer tasks until this loop is done.
   */
  npa_scheduler.next_timeout_state = NPA_SCHEDULER_NTS_OPEN;

  /* Setup timer that may have changed */
  npa_setup_next_timeout();
            
  /* done with main workloop.  The rest can be interrupted */
  Core_MutexUnlock(npa_scheduler.scheduler_work_lock);

  /* calculate function duration and record max */
  func_duration = npa_calc_duration(start_time,
                                    CoreTimetick_Get64(),
                                    &npa_scheduler.stats.run_requests_duration);

  ULOG_RT_PRINTF_4( npa_scheduler.log,
                    "END npa_run_scheduler_requests %d"
                    " (function_duration 0x%08x)"
                    " (req head: 0x%08x)"
                    " (fork head: 0x%08x)", 
                    npa_scheduler.stats.num_run_scheduler_requests++,
                    (uint32)func_duration,
                    npa_scheduler.request_queue.head,
                    npa_scheduler.forked_queue.head);

  /* done with the clock */
  if( npa_scheduler.clk_cpu_client)
  { /* client exists so use can make requests to the clock */
    npa_complete_request(npa_scheduler.clk_cpu_client);
  }
}


/**
 * <!-- npa_run_scheduler_forks -->
 *
 * @brief
 *
 * @param wakeup_time: information about signal causing the function to be called
 */
void npa_run_scheduler_forks(uint64 wakeup_time)
{
  npa_client_handle client;
  npa_client_handle next_client;
  npa_scheduler_data *request_ptr;
  uint64 absolute_time = 0;
  uint64 max_handle_time;
  uint64 current_time;
  uint32 tell_sleep = 0;
  uint32 num_forked = 0;
  uint32 num_fork_short_circuit = 0;
  uint32 num_implied_completes = 0;
  uint32 max_time_adjusted = 0;
  int64 due_time_delta = 0;
  uint64 timer_adjust = 0;

  /* must be in sleep and forked queue must be empty.
   * This could be caused by being called by something other than
   * npa_scheduler_lpr_enter() or npa_scheduler_lpr_exit(), was either
   * not run, or it ran but the notify didn't happen before sleep
   * called the enter function again.
  */
  CORE_LOG_VERIFY(
    (npa_scheduler.sleep.enter && NULL == npa_scheduler.forked_queue.head),
     ULOG_RT_PRINTF_0(npa.log, "ERROR Colliding npa_run_scheduler_forks()"));

  /* Request queue should not be empty.  The LPR should have been turned
   * off and Sleep should not have called enter function.
   */
  CORE_LOG_VERIFY(npa_scheduler.request_queue.head,
                  ULOG_RT_PRINTF_0(npa.log,
                    "ERROR npa_run_scheduler_forks called with an "
                    "empty request queue."));

  /* get first client of request list */
  client = npa_scheduler.request_queue.head;

  /* End time for finding requests to run in the LPR is sleep
   * wake time fork lookahead delta.  This will find the
   * first request that is due close to the exit time.
   * If one is found in the loop, then use the completion time
   * of the first one found plus reschedule time.
   * This will find all the requests that are grouped together
   * and run them all in the LPR.
   *
   * Need to also take into account the timer queue latency as sleep
   * has been told to account for this latency too and if it is bigger
   * than fork lookahead delta, sleep will be waking up earlier for us
   * but we won't fork since it is too early.
   */
  max_handle_time = wakeup_time
                    + npa_scheduler.config_ptr->fork_lookahead_delta
                    + npa_scheduler.config_ptr->timer_queue_latency;

  /* Issue request to the "/protocol/rpm/polling_mode" resource to
     switch the NPA remoting driver into polling mode */
  npa_issue_required_request( npa_scheduler.rpm_polling_mode_client, 1 );

  do
  { /* for all clients check if should fork or issue implied complete */
    request_ptr = client->request_ptr;
    next_client = request_ptr->next; /* remember next one because this one
                                      * may come off the queue.
                                      */

    due_time_delta = npa_compare_times(request_ptr->start_time, 
                                       max_handle_time);

    if ((due_time_delta <= 0)
        && npa_resource_has_attribute(client->resource, 
                                      NPA_RESOURCE_LPR_ISSUABLE)
        && 0 == npa_no_forks_allowed)
    { /* It is due, Sleep Forkable, and forking allowed so handle it */
      ULOG_RT_PRINTF_3( npa.log,
                        "\tNPA Scheduled Request LPR"
                        " (handle: 0x%08x)"
                        " (client: \"%s\")"
                        " (new_request: %d)",
                        client,
                        client->name,
                        request_ptr->new_request);

      /* take it off the request list.  We will put it the
       * forked list below.
       */
      npa_scheduler_remove(client,
                           NPA_DONT_UPDATE_START_TIMES,
                           NPA_LOCK_LIST);

      /* put back the original request so no dangling pointer to
       * scheduler routines and in case other routines use 
       * this field.
       */
      client->issue_request = request_ptr->issue_request;
        
      if (request_ptr->new_request)
      { /* issue only if it is a new request */
        npa_work_request pending_request;

        /* mark that we are forking.  npa_scheduler_sort_insert()
         * will put back on the list with the proper state.
         */
        request_ptr->state = NPA_SCHEDULED_CLIENT_FORKING;

        ++npa_scheduler.stats.forked;
        ++request_ptr->stats.forked;
        ++num_forked;

        /* Save the pending request and after issue restore as pending
         * request. This is to allow the implied complete logic to correctly
         * schedule the pending request later, if it needed to apply the
         * complete
         */
        memcpy(&pending_request, &(NPA_PENDING_REQUEST(client)),
               sizeof(pending_request));

        /* Indicate to the resource that this request applies at next wakeup */
        npa_set_request_attribute(client, NPA_REQUEST_NEXT_AWAKE);

        /* time duration of the issue request */
        request_ptr->stats.last_issue_fork_time
          = current_time = CoreTimetick_Get64();

        /* run the request */
        client->issue_request(client, 1);

        npa_calc_duration(current_time,
                          CoreTimetick_Get64(),
                          &request_ptr->stats.fork_issue_request_duration);

        /* Restore the pending request structure; this is only useful when
         * implied completes apply
         */
        memcpy(&(NPA_PENDING_REQUEST(client)), &pending_request,
               sizeof(pending_request));

        /* If it had an executed implied complete, set it back to pending
         * in case there is another early wakeup.
         */
        if (NPA_IMPLIED_COMPLETE_EXECUTED == request_ptr->implied_state)
        { /* move back to pending */
            request_ptr->implied_state = NPA_IMPLIED_COMPLETE_PENDING;
        }
      }
      else
      { /* short circuiting since not a new request */     
        ++npa_scheduler.stats.fork_short_circuits;
        ++request_ptr->stats.fork_short_circuits;
        ++num_fork_short_circuit;
      }

      /* wake work is now just notify work
       * Must update before putting on the list so the
       * list's work time is correct.
       */ 
      request_ptr->active_latency.wake = request_ptr->active_latency.notify;

      /* put in forked list */
      npa_scheduler_sort_insert(client, 
                                &npa_scheduler.forked_queue, 
                                NPA_DONT_UPDATE_START_TIMES);
      
      /* npa_scheduler_sort_insert sets state to LINKED, change
       * to show it is expecting to notified
       */
      request_ptr->state = NPA_SCHEDULED_CLIENT_NOTIFY_EXPECTED;

      if (!max_time_adjusted)
      { /* Adjust the max_handle_time once to be based upon the completion
         * time of this first Forkable request.  This is so all request that
         * end around this time get done together.
         */
        /* calculate time if request_time is past handle time. */
        uint64 adjusted_handle_time
          = request_ptr->request_time 
            + npa_scheduler.config_ptr->min_reschedule_delta;

        uint64 delta_handle_time;

        delta_handle_time = npa_compare_times(adjusted_handle_time,
                                              max_handle_time);

        if (delta_handle_time > 0)
        { /* adjusted_handle_time is farther out so use it. */
          max_handle_time = adjusted_handle_time;
        }

        /* do this only once */
        max_time_adjusted = 1;
      }
    }
    else if ((due_time_delta > 0)
             && NPA_IMPLIED_COMPLETE_PENDING == request_ptr->implied_state)
    { /* implied complete is needed as request won't fire when we wake */

      /* remove from implied complete list */
      npa_list_Remove(&npa_scheduler.implied_completes_now_list, client);

      /* Indicate to the resource that this request applies at next wakeup */
      npa_set_request_attribute(client, NPA_REQUEST_NEXT_AWAKE);

      /* it is still on request queue so just issue implied complete.
       * The amount of work should stay the same as the request queue
       * always has the worst case amount of work to do. 
       */ 
      npa_issue_implied_complete(client);

      ++num_implied_completes;
    }
    client = next_client; /* next item in original list */
  } while(client != NULL);

  /* Complete request to the "/protocol/rpm/polling_mode" resource to
     switch the NPA remoting driver back into barrier mode */
  npa_complete_request( npa_scheduler.rpm_polling_mode_client );
  
  if (npa_scheduler.forked_queue.num_linked_clients)
  { /* put something on the list so things changed.
     * Note that it may have went on the lists but it was not sent
     * to the RPM since it was not new so we need to sort even though
     * the request_started is false
     */
    /* Because things may have come out in-between items, we
     * need to scan the whole list.
     */
    npa_update_start_time(npa_scheduler.request_queue.tail, 
                          NPA_DO_COMPLETE_LIST);

    /* make sure start times for forked requests are correct too. 
     * Since this is first time to touch them in this list, do
     * the complete list
     */
    npa_update_start_time(npa_scheduler.forked_queue.tail,
                          NPA_DO_COMPLETE_LIST);

  
    /* Need to check if the next timeout should be driven by the 
     * request queue or the forked queue as the timeout has to occur
     * early enough to meet the request times of the clients in the
     * forked queue too.
     */
    if (NULL != npa_scheduler.request_queue.head)
    { /* something in request queue so base time on it */
      /* absolute start time is start time from head of queue
       * minus the notify work in the forked queue
       */
      absolute_time 
        = npa_scheduler.request_queue.head->request_ptr->start_time
          - npa_scheduler.forked_queue.sum_wake_work;
  
      if (NULL != npa_scheduler.forked_queue.head /* Klocworks */
          && NULL != npa_scheduler.forked_queue.head->request_ptr
          && (absolute_time > npa_scheduler.forked_queue.head->request_ptr->start_time))
      { /* have forked requests too and they start earlier than the request's
         * earliest start minus the work to do for the notify work so use
         * this time instead.
         */
        absolute_time 
          = npa_scheduler.forked_queue.head->request_ptr->start_time;
      }
  
      /* tell sleep but not timer */
      tell_sleep = 1;
    }
    else if (NULL != npa_scheduler.forked_queue.head->request_ptr)
    { /* just work in the forked queue */
  
      absolute_time 
        = npa_scheduler.forked_queue.head->request_ptr->start_time;
  
      tell_sleep = 1;
    }
    /* else not sure why nothing is in the list, but just ignore.
     * timer will fire when we wake up and solve the issue.
     */

    /* tell sleep */
    if (npa_scheduler.sleep.lpr_client
        && npa_sleep_lpr_supported
        && tell_sleep)
    { /* have a request in NAS so need to tell sleep about the time change */
      int64 request_delta = 0;
      time_timetick_type timer_expire_delta = 0;

      /* remember when need to start run_scheduler_requests by */
      npa_scheduler.next_scheduler_time = absolute_time;

      /* account for scheduler latency, sleep wake time, and 
       * runtime lpr adjustment
       */
      absolute_time 
        -= npa_scheduler.config_ptr->sched_latency
           + npa_scheduler.config_ptr->sleep_wake_transition_latency
           + npa_scheduler.adjust.lpr;

      /* test for timer needing to fire before the NPA Scheduler
       * task is done upon wakeup
       */
      timer_expire_delta = timer_get_time_till_first_non_deferrable_timer_64();

      if (0 != timer_expire_delta)
      { /* timer has an expire value in the future */
        current_time = CoreTimetick_Get64();
        /* find time until tail's request time */
        request_delta
          = npa_compare_times(npa_scheduler.forked_queue.tail->request_ptr->request_time,
                              current_time);

        /* difference between tail's request time and timer needing to fire */
        timer_adjust = npa_compare_times(request_delta,
                                         timer_expire_delta);

        if (timer_adjust > 0)
        { /* timer is due to fire before finished with requests
           * so adjustment is needed.
           */
          absolute_time -= timer_adjust;
          npa_scheduler.next_scheduler_time -= timer_adjust;

          /* stats on how much we change */
          npa_calc_duration(timer_adjust, 0,
                            &npa_scheduler.stats.nas_timer_adjustment);
        }
      }

      /* Tell sleep new wake time */
      sleep_npa_scheduler_adjust_deadline(absolute_time);

      /* This is the time we expect to wake up by */
      npa_scheduler.timer.current_timeout = absolute_time;
    }
  }

  ULOG_RT_PRINTF_8( npa_scheduler.log,
                    "DONE npa_run_scheduler_forks"
                    " (current_timeout:0x%016llx)"
                    " (max_handle_time: 0x%016llx)"
                    " (sleep_wakeup_time: 0x%016llx)"
                    " (timer_adjust: 0x%08x)"
                    " (tell_sleep: %d)",
                    ULOG64_LOWWORD(npa_scheduler.timer.current_timeout),
                    ULOG64_HIGHWORD(npa_scheduler.timer.current_timeout),
                    ULOG64_LOWWORD(max_handle_time),
                    ULOG64_HIGHWORD(max_handle_time),
                    ULOG64_LOWWORD(wakeup_time),
                    ULOG64_HIGHWORD(wakeup_time),
                    (int32) timer_adjust,
                    tell_sleep);
  ULOG_RT_PRINTF_3( npa_scheduler.log,
                    "       (num_forked: %d)"
                    " (num_fork_short_circuit: %d)"
                    " (num_implied_completes: %d)",
                    num_forked,
                    num_fork_short_circuit,
                    num_implied_completes);
}


/**
 * <!-- npa_run_scheduler_notifies -->
 * 
 * @brief Handle all pending scheduler notifies.
 *
 */
static void npa_run_scheduler_notifies(void)
{
  npa_client_handle client;
  npa_scheduler_data *request_ptr = NULL;
  uint64 latest_handle_time = 0;
  int did_implied_complete = 0;
  int64 delta = 0;

  if (NULL == npa_scheduler.forked_queue.head)
  {
    return;
  }

  /* Notifies can be called by the scheduler and client threads
   * so we need to protect it.  Note that since only things 
   * that hold this lock also only touch the fork queue, 
   * we don't need to lock the queue. 
   */
  Core_MutexLock(npa_scheduler.scheduler_work_lock);

  ULOG_RT_PRINTF_2( npa_scheduler.log,
                    "    npa_run_scheduler_notifies"
                    " (forked head: 0x%0x)"
                    " (forked count: %d)",
                    npa_scheduler.forked_queue.head,
                    npa_scheduler.forked_queue.num_linked_clients);
  
  /* there is a race condition where we didn't get
   * the lock until after another task already did the work
   * so check to see if anything still needs to be done.
   */
  if (npa_scheduler.forked_queue.num_linked_clients)
  { /* have something to do */

    /* calculate a latest handle time that are valid for
     * this wakeup time. If start times are later than that, we need to 
     * handle the implied completes to turn off the last NAS as it is not
     * needed.
     */
    latest_handle_time = CoreTimetick_Get64()
                         + npa_scheduler.config_ptr->auto_complete_delta;

    /* See how soon the first forked request is.  Need to do this only once
     * as if it is too early for the first, it is too early for all the
     * rest
     */
    delta 
      = npa_compare_times(latest_handle_time, 
                  npa_scheduler.forked_queue.head->request_ptr->request_time);

    do
    { /* loop and decide if need to do implied complete (backout) request
       * and put the request back on request queue 
       * or just issue the notify.
       */
      client = npa_scheduler_remove(npa_scheduler.forked_queue.head,
                                    NPA_DONT_UPDATE_START_TIMES,
                                    NPA_DONT_LOCK_LIST);

      request_ptr = client->request_ptr;

      if(( delta < 0)
         && (NPA_IMPLIED_COMPLETE_PENDING == request_ptr->implied_state))
      { /* woke up early so complete the request and put back on request queue */
        ULOG_RT_PRINTF_6( npa_scheduler.log,
                          "  Need Implied Complete"
                          " (client: 0x%08x)"
                          " (delta: 0x%x)"
                          " (latest_handle_time: 0x%016llx)"
                          " (start_time:0x%016llx)",
                          client,
                          (uint32) delta,
                          ULOG64_LOWWORD(latest_handle_time),
                          ULOG64_HIGHWORD(latest_handle_time),
                          ULOG64_LOWWORD(request_ptr->start_time),
                          ULOG64_HIGHWORD(request_ptr->start_time));

        /* Remove from the implied complete list if it is on it */
        npa_list_Remove(&npa_scheduler.implied_completes_now_list, client);

        /* put back on request queue */
        npa_scheduler_sort_insert(client, 
                                  &npa_scheduler.request_queue,
                                  NPA_DONT_UPDATE_START_TIMES);

        /* issue the complete and update start time */
        npa_issue_implied_complete(client);

        /* we did the implied complete and need to update timer later */
        did_implied_complete = 1;
      }
      else
      { /* notify the clients with their callbacks */
        npa_scheduler_notify(client, NULL);
      }
    } while (0 != npa_scheduler.forked_queue.num_linked_clients);

    if (did_implied_complete)
    { /* Changed the request queue so sort it then
       * setup timer that may have changed.
       * This will short circuit if called within the NPA Scheduler thread
       */
      npa_update_start_time(npa_scheduler.request_queue.tail, 
                            NPA_DO_COMPLETE_LIST);
      npa_setup_next_timeout();
    }
  }

  /* done with critical section */
  Core_MutexUnlock(npa_scheduler.scheduler_work_lock);

  ULOG_RT_PRINTF_2( npa_scheduler.log,
                    "  DONE - npa_run_scheduler_notifies"
                    " (latest_handle_time: 0x%016llx)",
                    ULOG64_LOWWORD(latest_handle_time),
                    ULOG64_HIGHWORD(latest_handle_time));
}


/**
 * <!-- npa_scheduler_sort_insert --> 
 * @brief Insert client into schedule link list.
 *
 * Takes a client and inserts it into the scheduled request link list
 * in sorted order going from closest to furthest request completion time.  
 *
 * @param client : Handle of the client for the request.  
 *                 Client handles are the same as the address
 *                 of the npa_client structure.
 * @param list_ptr : List for the insert
 * @param update_start_times : Update the clients (and all previous
 *                             clients in the list when needed) if true.
 *                             Ignored if the list is not sorted.
 *
 * Client's scheduled request state will be changed to NPA_SCHEDULED_CLIENT_LINKED
 */
static void npa_scheduler_sort_insert(npa_client_handle client,
                                      npa_scheduler_queue_struct *list_ptr,
                                      int update_start_times
                                      )
{
  npa_client_handle cptr = NULL;
  npa_scheduler_data *request_ptr;

  CORE_VERIFY_PTR(client);
  CORE_VERIFY_PTR(request_ptr = client->request_ptr);
  CORE_VERIFY(NULL == request_ptr->my_queue); /* not already on a queue*/

  /* make sure element is not linked to anything */
  request_ptr->next = request_ptr->prev = NULL;

  /* remember list this client is in */
  request_ptr->my_queue = list_ptr;

  /* Lock scheduled list */
  Core_MutexLock(list_ptr->lock);

  if (!list_ptr->not_sorted)
  { /* so search for insert point */
    /* setup an invalid start time so it doesn't hit by coincedence */
    request_ptr->start_time = request_ptr->request_time + 1;

    /* sort entry w.r.t. request time.
     * Look for the entry that has a time greater than the new one.
     */
    for (cptr = list_ptr->head;
           NULL != cptr 
           && (request_ptr->request_time >= cptr->request_ptr->request_time);
             cptr = cptr->request_ptr->next)
    { /* client's time is less than the list element's time.
       * Do nothing, just look for next insert location in list */
      CORE_VERIFY(cptr != client); /* test code */
    }
  }
  else
  { /* just throw on at tail */
    cptr = NULL;
  }

  /* at this point, cptr point's to the spot to insert before.
     NULL means at end of list and possibly list is empty.
  */

  /* point to the next element or NULL as the case may be */
  request_ptr->next = cptr;

  if (NULL != cptr)
  { /* have a link after so grab its prev pointer */
    request_ptr->prev = cptr->request_ptr->prev;
  }
  else
  { /* at tail */
    request_ptr->prev = list_ptr->tail;
    list_ptr->tail = client;
  }

  if (cptr == list_ptr->head)
  { /* insert new item at head */
    list_ptr->head = client;
  }
  if (NULL != request_ptr->prev)
  { /* there is an element before so update its next */
    request_ptr->prev->request_ptr->next = client;
  }
  if (NULL != request_ptr->next)
  { /* there is an element after so update its prev */
    request_ptr->next->request_ptr->prev = client;
  }

  /* Now in Linked state */
  request_ptr->state = NPA_SCHEDULED_CLIENT_LINKED;

  ++list_ptr->num_linked_clients;

  if (list_ptr->num_linked_clients > list_ptr->high_watermark)
  { /* keep track of the max elements in the list */
    list_ptr->high_watermark = list_ptr->num_linked_clients;
  }

  /* remember how much work this queue has in it */
  list_ptr->sum_wake_work += request_ptr->active_latency.wake;

  /* update the start time if directed and a sorted list */
  if (update_start_times && !list_ptr->not_sorted)
  {
    npa_update_start_time(client,NPA_DONT_DO_COMPLETE_LIST);
  }
  Core_MutexUnlock(list_ptr->lock);
}


/**
 * <!-- npa_scheduler_remove -->
 *
 * @brief Remove client from schedule link list.
 *
 * Takes a client and removes it from the link list
 * that it is in, else it does nothing.
 * 
 * @param client : Handle of the client for the request.  
 *                 Client handles are the same as the address
 *                 of the npa_client structure.
 * @param update_start_times : Update the clients (and all previous
 *                             clients in the list when needed) if true.
 * @param lock_list : True if list needs to be locked for the action.
 *
 * @return client handle
 * 
 * @sa This might be a blocking call on the scheduler list.
 *
 * Client's scheduled request state will be changed to
 * NPA_SCHEDULED_CLIENT_UNLINKED if remove was successful.
 */
static npa_client_handle npa_scheduler_remove (npa_client_handle client,
                                               uint32 update_start_times,
                                               uint32 lock_list)
{
  npa_scheduler_data *request_ptr;
  npa_scheduler_queue_struct *list_ptr;
   
  if (NULL == client)
  { /* not real client so just ignore */
    return(client);
  }

  /* Should only be called on schedulable clients
   * in a queue
   */
  CORE_VERIFY(NULL != client->request_ptr);

  request_ptr = client->request_ptr;

  list_ptr = request_ptr->my_queue;

  if (list_ptr)
  { /* client in link list so we can remove it */

    if (NPA_LOCK_LIST == lock_list)
    { /* caller wants the list locked */
      Core_MutexLock(list_ptr->lock);
    }
    /* no longer in this list */
    request_ptr->my_queue = NULL;

    if (list_ptr->head == client)
    { /* at list head */
      list_ptr->head = request_ptr->next;
    }
    if (list_ptr->tail == client)
    { /* at list tail */
      list_ptr->tail = request_ptr->prev;
    }
    if (request_ptr->next)
    { /* update item following */
      request_ptr->next->request_ptr->prev 
        = request_ptr->prev;
    }
    if (request_ptr->prev)
    { /* update item preceeding */
      request_ptr->prev->request_ptr->next 
        = request_ptr->next;
    }

    if (NPA_UPDATE_START_TIMES == update_start_times)
    { /* asked to update start times, request is now out of
       * list so update before loose prev pointer
       */
      npa_update_start_time(request_ptr->prev, NPA_DONT_DO_COMPLETE_LIST);
    }
    /*no dangling pointers */
    request_ptr->prev = request_ptr->next = NULL;

    request_ptr->state = NPA_SCHEDULED_CLIENT_UNLINKED;
    --list_ptr->num_linked_clients;
    
    /* work no longer counted but do protect from wrap in case 
     * something got off.  This will clear itself up when the list
     * goes empty.
     */   
    list_ptr->sum_wake_work -= MIN(request_ptr->active_latency.wake,
                                   list_ptr->sum_wake_work);


    if (NPA_LOCK_LIST == lock_list)
    { /* have a list so unlock it */
      Core_MutexUnlock(list_ptr->lock);
    }
  }
  /* else ignore */

  return(client);
}


#ifdef NPA_SCHEDULER_SLEEP_LPR_SUPPORTED
/**
 * <!-- is_lpr_work_soon -->
 *
 *  @brief see if an RPM dependent request is going to fire on the next timeout.
 *
 * @return 1 if there is one that will fire, 0 if not
 */
NPA_INLINE int is_lpr_work_soon(void)
{
  npa_client_handle client;

  if (NULL != npa_scheduler.forked_queue.head)
  { /* something in fork queue so it is soon */
    return(1);
  }

  /* Check if any LPR issuable client in request queue */
  for (client = npa_scheduler.request_queue.head;
        client;
        client = client->request_ptr->next)
  {
    if (npa_resource_has_attribute(client->resource, NPA_RESOURCE_LPR_ISSUABLE))
    { /* something to run in LPR */
      return(1);
    }
  }

  /* nothing in the queue is LPR issuable so ignore */
  return (0);
}
#endif /* NPA_SCHEDULER_SLEEP_LPR_SUPPORTED */


/**
 * <!-- npa_scheduler_enable_timer -->
 *
 * @brief Update the Scheduler timer and notify sleep lpr of the change
 *
 * Note - Should always be called in a thread safe environment.
 *
 * @param start_ttick : TTICK absolute time for next timer event
 * @param sleep_deadline : Deadline information for sleep
 * @param timer_latency : TTICKS to account for timer triggering latency
 *
 */
static void npa_scheduler_enable_timer(uint64 start_ttick,
                                       uint64 sleep_deadline,
                                       uint64 timer_latency)
{
  uint64 delta_ttick;
  uint64 current_time = CoreTimetick_Get64();
  uint64 timer_start = start_ttick - timer_latency; /* adjust for latency */

  /* remember time need to run by */
  npa_scheduler.next_scheduler_time = start_ttick;

  /* setup next timeout.
   * this takes into account the non-sleep timer queue latency
   */
  npa_scheduler.timer.current_timeout = timer_start;

  if (timer_start > current_time)
  { /* positive delta so use it */
    delta_ttick = timer_start - current_time;
  }
  else
  { /* time_start is in the past so set delta to zero */
    delta_ttick = 0;
  }

  timer_set_64( &npa_scheduler.timer.timer, delta_ttick, 0, T_TICK );

  /* Tell sleep the time we must be awake (may be UINT64_MAX, implying no
   * deadline). The deadline will get adjusted out if the NPA Scheduler LPR
   * mode is chosen.
   */
  sleep_npa_scheduler_set_deadline(sleep_deadline);
  npa_scheduler.sleep.last_sleep_deadline = sleep_deadline;

#ifdef NPA_SCHEDULER_SLEEP_LPR_SUPPORTED
  if (npa_scheduler.sleep.lpr_client
      && npa_sleep_lpr_supported)
  { /* have a Sleep LPR and we want to talk to it. */
    if (is_lpr_work_soon())
    { /* A request will fire in next timeout */
      if (1 != npa_scheduler.sleep.lpr_state_on)
      { /* LPR is off.  Enable the lpr. */
        /* There is only one mode so bit 0 is used */
        npa_issue_required_request( npa_scheduler.sleep.lpr_client, SLEEP_LPRM_NUM(0) );
        npa_scheduler.sleep.lpr_state_on = 1;
      }
    }
    else if (1 == npa_scheduler.sleep.lpr_state_on)
    { /* no request but LPR is on, so turn off */
      npa_scheduler.sleep.lpr_state_on = 0;
      npa_complete_request(npa_scheduler.sleep.lpr_client);
    }
  }
#endif

  ULOG_RT_PRINTF_8( npa_scheduler.log, 
                    "  DONE npa_scheduler_enable_timer"
                    " (start_ttick: 0x%016llx)"
                    " (timer_latency: 0x%016llx)"
                    " (delta: 0x%016llx)"
                    " (sleep_deadline: 0x%016llx)",
                    ULOG64_LOWWORD(start_ttick),
                    ULOG64_HIGHWORD(start_ttick),
                    ULOG64_LOWWORD(timer_latency),
                    ULOG64_HIGHWORD(timer_latency),
                    ULOG64_LOWWORD(delta_ttick),
                    ULOG64_HIGHWORD(delta_ttick),
                    ULOG64_LOWWORD(sleep_deadline),
                    ULOG64_HIGHWORD(sleep_deadline));
}


/**
 * <!-- npa_scheduler_disable_timer -->
 *
 * @brief Cancel the Scheduler timer and notify sleep lpr of the change
 *
 * @note Should always be called in a thread safe environment.
 */
void npa_scheduler_disable_timer(void)
{
  uint64 remaining;

  /* clear the timer and log the number of ticks timer thinks it has
   * until its next expiry.
   */
  remaining = timer_clr_64(&npa_scheduler.timer.timer, T_TICK);

  /* Tell sleep the deadline info it may have is no longer valid */ 
  sleep_npa_scheduler_cancel_deadline();

#ifdef NPA_SCHEDULER_SLEEP_LPR_SUPPORTED
  if (npa_sleep_lpr_supported)
  {
    if (1 == npa_scheduler.sleep.lpr_state_on)
    { /* lpr enabled so disable lpr */
      npa_complete_request(npa_scheduler.sleep.lpr_client);
      npa_scheduler.sleep.lpr_state_on = 0;
    }
  }
#endif

  ULOG_RT_PRINTF_2( npa_scheduler.log, 
                    "  npa_scheduler_disable_timer "
                    " (timer_expiry_ticks: 0x%016llx)",
                    ULOG64_LOWWORD(remaining),
                    ULOG64_HIGHWORD(remaining));
}


/**
 * <!-- npa_scheduler_signal_task -->
 *
 * @brief Send signal to the NPA Scheduler task
 *
 * @param sig: Signal to send to the NPA Scheduler task.
 */
void npa_scheduler_signal_task(npa_scheduler_action_type sig)
{
  /* valid range for sig is between 0 and UNDEFINED */
  CORE_LOG_VERIFY(NPA_SCHEDULED_ACTION_UNDEFINED > sig,
                  ULOG_RT_PRINTF_1( npa_scheduler.log, 
                                    "ERROR npa_scheduler_signal_task"
                                    " - signal %d is out of range",
                                    sig )
                  );

  /* send the event */
  CORE_DAL_VERIFY( DALSYS_EventCtrl( npa_scheduler.events_array[sig], 
                                     DALSYS_EVENT_CTRL_TRIGGER ) );
}


/**
 * <!-- npa_setup_next_timeout -->
 *
 * @brief  Calculates and setup Scheduler Time Out
 * 
 * Calculates the next desired timeout w.r.t. the Scheduled Request list.
 * If no requests are pending, it will make sure the timer is turned off
 * (although there still could be race condition and it still fires.
 *
 * If the request is more than half the wrap time, then assume it is actually
 * late and declare it as 0 and poke the scheduler to handle it.
 *
 * It is not ran in this context since it would be another client's request
 * and we don't want to muddy up the current task with other task's work.
 *
 *  @sa This can block on npa_scheduler.request_queue.lock.
 */
static void npa_setup_next_timeout()
{
  npa_client_handle client_ptr;
  npa_client_handle complete_ptr;
  uint64 start_time = 0;
  uint64 reschedule_time;
  uint64 complete_start_time = UINT64_MAX; /* MAXINT means not set */
  uint64 request_start_time  = UINT64_MAX;
  uint64 timer_latency = 0; /* assume complete queue */
  uint64 sleep_deadline = UINT64_MAX;

  if (NPA_SCHEDULER_NTS_NO_SETUP == npa_scheduler.next_timeout_state)
  { /* scheduler is running so don't need to setup timeout or pokes.
     * No race condition though since the callers request should already
     * be in the queue so scheduler task will see it.
     * If scheduler sneaks in right after the test, then we will do nothing
     * since the timeout will already be correct below.
     */
    return;
  }

  Core_MutexLock(npa_scheduler.request_queue.lock);
  Core_MutexLock(npa_scheduler.complete_queue.lock);

  client_ptr = npa_scheduler.request_queue.head;
  complete_ptr = npa_scheduler.complete_queue.head;

  if (NULL == client_ptr && NULL == complete_ptr)
  { /* Disable timer, cancel sleep deadline and disable LPRM */
    npa_scheduler_disable_timer();

    Core_MutexUnlock(npa_scheduler.complete_queue.lock);
    Core_MutexUnlock(npa_scheduler.request_queue.lock);

    return; /* nothing to schedule */
  }

  if (client_ptr)
  { /* have a request queue item so setup desired start time */
    /* Calculate start time for request queue 
    * as it must finish before request time.
    */
    request_start_time = client_ptr->request_ptr->start_time
                         - npa_scheduler.config_ptr->sched_latency;

    /* New deadline to sleep */
    sleep_deadline = request_start_time 
                     - npa_scheduler.config_ptr->sleep_wake_transition_latency;
  }

  if (complete_ptr)
  {
    complete_start_time = complete_ptr->request_ptr->start_time;
  }

  /* else have a timeout value, make sure next event is correct */
  
  reschedule_time = CoreTimetick_Get64(); /* Set for complete queue s.t.
                                           * only things in the past will
                                           * fire.
                                           */

  if (request_start_time > complete_start_time)
  { /* request queue's start time is after complete's start time so
     * complete should drive timer.
     */
    start_time = complete_start_time;

    /* don't want the timer to fire early for complete queue */
    timer_latency = 0;
  }
  else
  { /* setup request queues start and reschedule time */
    /* need to take into account the timer queue latency time */
    start_time = request_start_time;

    /* need to make sure we wake up soon enough for the timer
     * overhead/latency
     */
    timer_latency = npa_scheduler.config_ptr->timer_queue_latency
                    + npa_scheduler.adjust.timer;

    /* need to handle all requests out past min_reschedule_delta time 
     * and timer latency
     */
    reschedule_time += npa_scheduler.config_ptr->min_reschedule_delta;
  }

  if (start_time >= reschedule_time)
  { /* far enough in the future so set timer */
    if (npa_scheduler.timer.current_timeout != start_time
        || !TIMER_IS_ACTIVE(&npa_scheduler.timer.timer)
        || 1 != npa_scheduler.sleep.lpr_state_on)
    { /* new time or timer/lpr are not active so schedule timeout */
      npa_scheduler_enable_timer(start_time, sleep_deadline, timer_latency);
    }
    /* else the timeout is already scheduled so nothing to do */
  }
  else if ( npa_scheduler.next_timeout_state == NPA_SCHEDULER_NTS_OPEN)
  { /* wants to happen now so trigger the scheduler and
     * the scheduler is not already poked. so poke it. */

    /* say that we are poking the scheduler.
     * We don't need to worry about this being cleared immediately
     * since the request is already in the scheduled list and it is
     * ok to poke again even if there is nothing to do.  Just trying to
     * cut down on the extra pokes.
     */
    npa_scheduler.next_timeout_state = NPA_SCHDEDULER_NTS_NO_POKE;

    ULOG_RT_PRINTF_10( npa_scheduler.log,
                      "  poke scheduler"
                      " (start_time: 0x%016llx)"
                      " (reschedule_time: 0x%016llx)"
                      " (latency : 0x%016llx)"
                      " (complete_start_time: 0x%016llx)"
                      " (request_start_time: 0x%016llx)",
                      ULOG64_LOWWORD(start_time),
                      ULOG64_HIGHWORD(start_time),
                      ULOG64_LOWWORD(reschedule_time),
                      ULOG64_HIGHWORD(reschedule_time),
                      ULOG64_LOWWORD(timer_latency),
                      ULOG64_HIGHWORD(timer_latency),
                      ULOG64_LOWWORD(complete_start_time),
                      ULOG64_HIGHWORD(complete_start_time),
                      ULOG64_LOWWORD(request_start_time),
                      ULOG64_HIGHWORD(request_start_time));

    /* Turn the timer/lpr off since we are poking.  It will be setup again
     * when the scheduler runs
     */
    npa_scheduler_disable_timer();

    /* Trigger scheduler that it has work to do if needed now */
    npa_scheduler_signal_task(NPA_SCHEDULED_ACTION_TRIGGER);
  }

  Core_MutexUnlock(npa_scheduler.complete_queue.lock);
  Core_MutexUnlock(npa_scheduler.request_queue.lock);
}


/**
 * <!-- npa_scheduler_handle_implied_complete -->
 *
 * @brief Issue the Implied Complete if needed
 *
 * Checks to see if an implied complete is pending on the client
 * and issues it if the system is busy
 *
 * @note This should only be run in the NPA Scheduler tread.
 *  
 * @param action : handle to action describing. (Not used)
 */
void npa_scheduler_handle_implied_complete(npa_scheduler_action *action)
{
  npa_client_handle client;
  npa_query_type query_result;
  npa_query_status qstatus;

  /* See if system is "busy" and thus should do the complete */
  qstatus = npa_query( npa_scheduler.core_cpu_busy_query_handle,
                      NPA_QUERY_CURRENT_STATE,
                      &query_result );

  if ((NPA_QUERY_UNKNOWN_RESOURCE == qstatus)
      || ((NPA_QUERY_SUCCESS == qstatus)
          && (0 != query_result.data.state)))
  { /* system is busy or not defined so need to issue the implied completes */
    Core_MutexLock(npa_scheduler.scheduler_work_lock);
    /* complete one request on the queue. */
    client = (npa_client_handle) 
                npa_list_PopFront(&npa_scheduler.implied_completes_now_list);
    if (client)
    { /* popped a client off of the list */
      CORE_VERIFY_PTR(client->request_ptr); /* Klocworks */
      /* Check if there is an implied complete and if it needs to run */
      if (NPA_IMPLIED_COMPLETE_PENDING == client->request_ptr->implied_state
          && NPA_SCHEDULED_CLIENT_LINKED == client->request_ptr->state)
      { /* Implied complete is pending and it is still linked in queue 
         * so OK to run the impled complete
         */
        npa_issue_implied_complete(client);

        /* Setup timer that may have changed */
        npa_setup_next_timeout();
      }
    }
    Core_MutexUnlock(npa_scheduler.scheduler_work_lock);

    if (npa_list_PeekFront(&npa_scheduler.implied_completes_now_list))
    { /* We need to allow the scheduler a chance to run so resignal
       * this event if there is more to do
       */
      npa_scheduler_signal_task(NPA_SCHEDULED_ACTION_IMPLIED_COMPLETE);
    }
  }
}


/**
 * <!-- npa_issue_scheduled_request -->
 *
 * @brief Set as the client->issue_request function to make the following 
 * request a scheduled client work request.
 *
 * Request will be either scheduled to run by the time setup by the
 * npa_create_scheduled_request() or immediately depending up
 * the time remaining until the calculated start time (based on
 * deadline, latency, et al). 
 *  
 * @param client : handle to client being used
 * @param new_request : requested resource state
 */
static void npa_issue_scheduled_request( npa_client_handle client, 
                                         int new_request )
{
  npa_scheduler_data *request_ptr = client->request_ptr;
  npa_query_type query_result;
  npa_query_status qstatus;
  npa_resource_latency *resource_latency;
  uint32 req_time, fork_time, notify_time;
  npa_resource *resource = client->resource;

  /* Must be in EXPECTING state else it is a hard error */
  if (NPA_SCHEDULED_CLIENT_EXPECTING != request_ptr->state)
  { /* Not in the expected state for issuing the request.
     * This could be due to another issue_request being
     * given on an already scheduled request.
     */
    ULOG_RT_PRINTF_3( npa.log,
                      "npa_issue_scheduled_request - unexpected state - "
                      " (handle: 0x%08x)"
                      " (client: \"%s\")"
                      " (state: \"%s\")",
                      client,
                      client->name,
                      npa_scheduled_client_state_name(request_ptr->state));
    CORE_VERIFY(0); /* fatal error */
  }

  /* Only user thread can touch client's data structure
   * until it is in the list. So no lock is needed until
   * the insert occurs.
   */

  /* save the new_request parameter to use later */
  request_ptr->new_request = new_request;

  /* setup the client's values though in case the resource
   * wants to take over on the request.  This means the new_request
   * and the issue_request values have to be set to desired values.
   */
  client->issue_request = request_ptr->issue_request;
  /* TODO - This now opens up a window where we may/may not have to handle
   * this request but cannot detect an illegal additional issue_request.
   * One solution is to not do the above and make it the responsiblity
   * of the resource to clean up.  Maybe we provide a function call
   * to do the cleanup?
   */

  /* set default latency */
  req_time = request_ptr->default_latency.request;
  fork_time = request_ptr->default_latency.fork;
  notify_time = request_ptr->default_latency.notify;

  /* Find what work can be done pre and post sleep.  If the
   * request is LPR Issuable, then the request can be handled 
   * in the NPA LPR routine when entering sleep.
   * If the routine is not LPR Issuable, then the request will be
   * called post wakeup.
   */
  /* request resource's latencies */
  /* Pass in the late_probability */
  query_result.data.value = request_ptr->late_probability;
  query_result.type = NPA_QUERY_TYPE_VALUE;
  qstatus = npa_query( (npa_query_handle) resource, 
                        NPA_QUERY_RESOURCE_LATENCY, 
                        &query_result );
  if (NPA_QUERY_UNSUPPORTED_QUERY_ID != qstatus)
  { /* resource gave latencies so use them */
    /* see if resource wants to handle the timeout itself */
    if (NPA_QUERY_TYPE_VALUE == query_result.type
        && 0 == query_result.data.value)
    { /* resource will handle so we are done */
      /** @todo How does resource know it needs to handle 
        * THIS client's request?  Should we pass the client handle?
        * -- Also, how does this resource know the deadline info?
        */
      ULOG_RT_PRINTF_4( npa.log, 
                        "npa_issue_scheduled_request (handle: 0x%08x)"
                        " (client: \"%s\" )"
                        "(resource: \"%s\") (Latency: %d) "
                        " - Resource will handle scheduling",
                        client,
                        client->name,
                        client->resource_name,
                        query_result.data.state);

      /* count it */
      ++request_ptr->stats.resource_handle_scheduling;

      /* restore original issue request */
      client->issue_request = request_ptr->issue_request;

      /* No implied complete */
      request_ptr->implied_state = NPA_NO_IMPLIED_COMPLETE;
      request_ptr->issue_request = NULL; /* no dangling pointers */

      /* Request is no longer active */
      request_ptr->state = NPA_SCHEDULED_CLIENT_INACTIVE;

      return;
    }

    /* resource must have returned a reference at this point if using the api
     * correctly */
    CORE_VERIFY(resource_latency = 
        (npa_resource_latency *)query_result.data.reference);
    if (resource_latency->request != 0xffffffff)
    {
      req_time = resource_latency->request;
    }
    if (resource_latency->notify != 0xffffffff)
    {
      /* set the notify latency */
      notify_time = resource_latency->notify;
    }
    /* if resource is lpr issuable, set the fork latency */
    if (resource_latency->fork != 0xffffffff)
    {
      fork_time = resource_latency->fork;
    }
  }

  /* set the found values in the client's structure */
  request_ptr->active_latency.request = req_time;
  request_ptr->active_latency.fork = fork_time;
  /* we always have notify work to do */
  request_ptr->active_latency.notify 
    = request_ptr->active_latency.wake = notify_time;
  
  /* determine amount of extra work to do */
  if (request_ptr->new_request
     || NPA_NO_IMPLIED_COMPLETE != request_ptr->implied_state )
  { /* request will not short circuit or there is a possiblity 
     * of an implied complte so wake latency 
     * is the additional request and any runtime adjustments
     */
    request_ptr->active_latency.wake 
      += req_time + request_ptr->active_latency.request_adjustment;
  }

  /* If the request is not a complete/cancel, then it goes on the
   * regular request list and will be ran s.t. it is done by
   * the request time.
   */
  if (NPA_PENDING_REQUEST(client).state)
  { /* Put in queue and update start times since things can
     * only shift to the left.
     */
    npa_scheduler_sort_insert(client, 
                              &npa_scheduler.request_queue, 
                              NPA_UPDATE_START_TIMES);
  }
  else
  { /* request is for a complete or cancel so put on the
     * complete list.  It will happen no sooner than request time.
     * Don't need to update start times since things can shift to
     * the right.
     */
    npa_scheduler_sort_insert(client, 
                              &npa_scheduler.complete_queue, 
                              NPA_DONT_UPDATE_START_TIMES);
    /* since we don't update the start time ever, we need to set
     * the start_time as npa_scheduler_sort_insert() puts in an
     * illegal value.
     */
    request_ptr->start_time = request_ptr->request_time;
  }

  /* Setup timer that may have changed, this will poke the scheduler
   * if this needs to run soon.
   */
  npa_setup_next_timeout();

  /* Check if there is an implied complete and if it needs to run */
  if (NPA_IMPLIED_COMPLETE_PENDING == request_ptr->implied_state)
  { /* have an implied complete */
    /* See if system is "busy" and thus should do the complete */
    qstatus = npa_query( npa_scheduler.core_cpu_busy_query_handle,
                        NPA_QUERY_CURRENT_STATE,
                        &query_result );

    if (NPA_QUERY_UNKNOWN_RESOURCE == qstatus ||
        (NPA_QUERY_SUCCESS == qstatus && 0 != query_result.data.state) ||
        !npa_resource_has_attribute(resource, NPA_RESOURCE_LPR_ISSUABLE))
    { /* system is busy or busy not defined yet
       * so need to issue the implied complete 
       */
      /* protect the list */
      Core_MutexLock(npa_scheduler.scheduler_work_lock);
      /* Add to the implied complete stack */
      npa_list_PushFront(&npa_scheduler.implied_completes_now_list, client);
      Core_MutexUnlock(npa_scheduler.scheduler_work_lock);
      /* Trigger scheduler thread to handle the implied complete */
      npa_scheduler_signal_task(NPA_SCHEDULED_ACTION_IMPLIED_COMPLETE);
    }
  }

  ULOG_RT_PRINTF_9( npa_scheduler.log,
                    "\tnpa_issue_scheduled_request"
                    " (client handle: 0x%08x)"
                    " (client: \"%s\")"
                    " (request time: 0x%016llx)"
                    " (start time: 0x%016llx)"
                    " (full latency: 0x%08x)"
                    " (fork latency: 0x%08x)"
                    " (notify latency: 0x%08x)",
                    client,
                    client->name,
                    ULOG64_LOWWORD(request_ptr->request_time),
                    ULOG64_HIGHWORD(request_ptr->request_time),
                    ULOG64_LOWWORD(request_ptr->start_time),
                    ULOG64_HIGHWORD(request_ptr->start_time),
                    req_time,
                    fork_time,
                    notify_time);
}


#ifdef NPA_SCHEDULER_SLEEP_LPR_SUPPORTED
/**
 * <!-- npa_init_scheduler_lpr_callback -->
 *
 * @brief All dependencies are now ready so initialize the npa_scheduler_lpr.
 *
 * During the scheduler initialization this is set as the resource available
 * callback for when the "npa_scheduler_lpr_init_resources" become available. 
 * All parameters are ignored but defined to meet calling convention.
 *
 * @param context : Not used
 * @param event_type: Not used
 * @param data : Not used
 * @param data_size: Not used
 */
static void npa_init_scheduler_lpr_callback( void *context,
                                             unsigned int event_type,
                                             void *data,
                                             unsigned int data_size)
{
  if (npa_sleep_lpr_supported)
  {/* Init and register the Scheduler Fork LPR */
    ULOG_RT_PRINTF_0( npa_scheduler.log,
                      "npa_init_scheduler_lpr_callback");

    npa_scheduler_lpr_init();

    /* we are working with sleep so timer needs to be deferrable
     * so sleep knows it is not a hard wakeup time.
     */
    timer_group_set_deferrable(&npa_scheduler.timer.group, 1);
  }
}
#endif /* NPA_SCHEDULER_SLEEP_LPR_SUPPORTED */


/**
 * <!-- npa_scheduler_timer_def -->
 *
 * @brief Setup NPA Scheduler timer
 * 
 */
static void npa_scheduler_timer_def(void)
{  /* Timer subsytem should now be up so setup timer interface 
    * Have callback send signal to workloop
    */
  timer_def( &npa_scheduler.timer.timer, 
             &npa_scheduler.timer.group, 
             NULL, 
             0,
             npa_scheduler_timeout_callback,
             0 );
}


/**
 * <!-- npa_scheduler_rpm_polling_mode_avail_cb -->
 *
 * @brief Create a client handle to the "/protocol/rpm/polling_mode" resource
 *
 * In npa_init_scheduler, this function is set as the resource available
 * callback for when "/protocol/rpm/polling_mode" becomes available.
 * All parameters are ignored but defined to meet calling convention.
 *
 * @param context : Not used
 * @param event_type: Not used
 * @param data : Not used
 * @param data_size: Not used
 */
static void npa_scheduler_create_rpm_polling_mode_client( void *context,
                                                          unsigned int event_type,
                                                          void *data,       
                                                          unsigned int data_size)
{
  npa_scheduler.rpm_polling_mode_client = 
    npa_create_sync_client( "/protocol/rpm/polling_mode",
                            "npa_scheduler_rpm_polling_mode_client",
                            NPA_CLIENT_REQUIRED );
  CORE_VERIFY_PTR( npa_scheduler.rpm_polling_mode_client );
}


/**
 * <!-- npa_init_scheduler_timer_callback -->
 *
 * @brief All dependencies are now ready for the scheduler timer so initialize.
 *
 * In npa_init_scheduler, this function is set as the resource available
 * callback for when "/init/timer" becomes available.
 * All parameters are ignored but defined to meet calling convention.
 *
 * @param context : Not used
 * @param event_type: Not used
 * @param data : Not used
 * @param data_size: Not used
 */
static void npa_init_scheduler_timer_callback( void *context,
                                        unsigned int event_type, 
                                        void *data,       
                                        unsigned int data_size)
{
  ULOG_RT_PRINTF_0( npa_scheduler.log,
                    "npa_init_scheduler_timer_callback");

  /* Timer subsytem should now be up so setup timer interface */
  npa_scheduler_timer_def();

  npa_scheduler.timer_up = 1;

#ifdef NPA_SCHEDULER_SLEEP_LPR_SUPPORTED
  /* need to wait until /sleep/lpr and RPM are up before
   * the scheduler lpr can be created.
   */
  if (npa_sleep_lpr_supported)
  { /* sleep lpr is supported so we want to set it up */
    npa_resources_available_cb( NPA_ARRAY(npa_scheduler_lpr_init_resources),
                                npa_init_scheduler_lpr_callback,
                                NULL);
  }
#endif
}


/**
 * <!-- npa_init_scheduler_clk_cpu_callback -->
 *
 * @brief Creates client linked to "clk/cpu"
 *
 * In npa_init_scheduler, this function is set as the resource available
 * callback for when "/clk/cpu" becomes available.
 * All parameters are ignored but defined to meet calling convention.
 *
 * @param context : Not used
 * @param event_type: Not used
 * @param data : Not used
 * @param data_size: Not used
 */
static void npa_init_scheduler_clk_cpu_callback( void *context,
                                                 unsigned int event_type,
                                                 void *data,
                                                 unsigned int data_size)
{
  /* Error if client is already created */
  CORE_VERIFY(NULL == npa_scheduler.clk_cpu_client);

  /* create the clk client */
  npa_scheduler.clk_cpu_client 
    = npa_create_sync_client( "/clk/cpu", 
                              "npa_scheduler_clk_cpu_client",
                              NPA_CLIENT_SUPPRESSIBLE );
  CORE_VERIFY_PTR(npa_scheduler.clk_cpu_client);
}


/**
 * <!-- npa_init_scheduler_core_cpu_busy_callback -->
 *
 * @brief Creates query handle to "core/cpu_busy"
 * 
 * In npa_init_scheduler, this function is set as the resource available
 * callback for when "/core/cpu/busy" becomes available.
 * All parameters are ignored but defined to meet calling convention.
 *
 * @param context : Not used
 * @param event_type: Not used
 * @param data : Not used
 * @param data_size: Not used
 */
static void npa_init_scheduler_core_cpu_busy_callback( void *context,
                                                       unsigned int event_type,
                                                       void *data,
                                                       unsigned int data_size)
{
  /* Error if query handle is already created */
  CORE_VERIFY(NULL == npa_scheduler.core_cpu_busy_query_handle);

  /* create CPU Busy Client for getting soft wakeup time */
  CORE_VERIFY_PTR( 
    npa_scheduler.core_cpu_busy_query_handle
      = npa_create_query_handle( "/core/cpu/busy" ) );

  CORE_VERIFY_PTR(npa_scheduler.core_cpu_busy_query_handle);
}


/**
 * <!-- npa_resource_overrides_list_add_uniquely -->
 *
 * @brief Walk the list. Replace or add the npa_resource_config.  
 *
 * @param list_ptr : Pointer to a npa_list_header to work on. 
 * @param add_ptr : An npa_resource_config to add
 */
static void npa_resource_overrides_list_add_uniquely(npa_list_header *list_ptr,
                                             const npa_resource_config *add_ptr)
{
  npa_list_elem *elem_ptr = NULL;

  CORE_VERIFY_PTR(list_ptr);
  CORE_VERIFY_PTR(add_ptr);

  while (add_ptr->name)
  { /* find if current name is unique in the list */
    for (elem_ptr = list_ptr->head; elem_ptr != NULL; elem_ptr = elem_ptr->next)
    {
      if (strncmp(((npa_resource_config *)(elem_ptr->data))->name, 
                  add_ptr->name, NPA_MAX_STR_LEN+1) == 0)
      { /* names match */
        break;
      }
    }

    if (elem_ptr)
    { /* found a match so overwrite */
      elem_ptr->data = (void *)add_ptr;
    }
    else
    { /* unique so push to beginning */
      npa_list_PushFront(list_ptr, (void *) add_ptr);
    }

    ++add_ptr;
  }
}


/**
 * <!-- npa_resource_overrides_config -->
 *
 * @brief Update resource configs if updates are available. 
 */
static void npa_resource_overrides_config( npa_list_header *list_ptr )
{
#ifdef NPA_USES_CORE_PROPERTY
  npa_resource_config *overrides_ptr = NULL;
  int property_status;

  /* Get npa_resource_overrides run time config data if exists.
   * overrides_ptr will not change if it doesn't exist
   */
  property_status = CoreProperty_GetPtr("/dev/power/npa/config",
                                        "resource_overrides",
                                        (const void **) &overrides_ptr);

  if ((CORE_PROPERTY_SUCCESS == property_status) && overrides_ptr )
  { /* updated version */
    ULOG_RT_PRINTF_0( npa.log,
        "npa_resource_overrides_config: Runtime NPA Resource Config found" );
    npa_resource_overrides_list_add_uniquely(list_ptr, overrides_ptr);
  }
    
  /* Get any possible target specific updates and new values. 
   * overrides_ptr will not change if it doesn't exist.
   */
  property_status = CoreProperty_GetPtr("/dev/power/npa/target/config",
                                        "resource_overrides",
                                        (const void **) &overrides_ptr);

  if ((CORE_PROPERTY_SUCCESS == property_status) && overrides_ptr )
  { /* update to current state version or prepend if unique */
    ULOG_RT_PRINTF_0( npa.log,
        "npa_resource_overrides_config: Target NPA Resource Config found" );
    npa_resource_overrides_list_add_uniquely(list_ptr, overrides_ptr);
  }

#else /* !NPA_USES_CORE_PROPERTY */
  /* create the list */
  npa_resource_overrides_list_add_uniquely(list_ptr, 
                                           npa_resource_overrides_data);
#endif /* NPA_USES_CORE_PROPERTY */
}


/**
 * <!-- npa_get_resource_override_latency -->
 * 
 * @brief Search for a resource name in npa_scheduler.overrides
 *
 * @param name : Name of resource to search for
 *
 * @return pointer to latencies if they exist else returns NULL
 */
npa_resource_latency_data 
  *npa_get_resource_override_latency(npa_list_header *list,
                                     const char *name)
{
  npa_list_elem *elem_ptr;
  npa_resource_config *data_ptr;

  CORE_VERIFY_PTR(name);

  for (elem_ptr = list->head; elem_ptr != NULL; elem_ptr = elem_ptr->next)
  { /* scan the list */
    data_ptr = (npa_resource_config *)(elem_ptr->data);
    if(strncmp(data_ptr->name, name, NPA_MAX_STR_LEN+1) == 0)
    { /* found it so return latency */
      return(&((npa_resource_config *)(elem_ptr->data))->latency);
    }
  }
  return((npa_resource_latency_data *) NULL);
}


/**
 * <!-- npa_compare_strings -->
 *
 * @brief Compare a string to a set of strings.
 *
 * @param st1: String to compare
 * @param list_ptr: Pointer to npa_list_header of strings for the comparison.
 * @param max_count: Maximum size of both strings
 *
 * @return 1 if st1 compares with any of the strings in the list else 0
 */
NPA_INLINE int npa_compare_strings(const char *st1, npa_list_header *list_ptr,
                                   unsigned int max_count)
{
  npa_list_elem *elem_ptr;

  CORE_VERIFY_PTR(st1);
  CORE_VERIFY_PTR(list_ptr);

  if (0 == max_count)
  { /* size is 0 so nothing to do */
    return(0);
  }

  for (elem_ptr = list_ptr->head;
       elem_ptr;
       elem_ptr= elem_ptr->next)
  { /* Walk down the list looking for a match */
    if (elem_ptr->data
        && strncmp(st1, (const char *) elem_ptr->data, max_count) == 0)
    { /* Have a match so return success */
      return 1;
    }
  }
  return 0;
}


/**
* <!-- npa_schedule_client_internal -->
*
* @brief Make the client schedule the next request.
*
* client and client->request_ptr must be valid on entry.
*/
static npa_client_handle 
npa_schedule_client_internal( npa_client_handle client, 
                              uint64 request_time, 
                              uint32 late_probability,
                              npa_scheduler_callback notification,
                              void * context )
{

  npa_scheduler_data *request_ptr = client->request_ptr;

  /* Make sure there is no previous request on client */
  CORE_LOG_VERIFY(NPA_SCHEDULED_CLIENT_INACTIVE == request_ptr->state,
                  ULOG_RT_PRINTF_3( npa.log,
                  "ERROR npa_schedule_client - unexpected state - "
                  "possible additional scheduled request on "
                  "client already"
                  " (handle: 0x%08x)"
                  " (client: \"%s\")"
                  " (state: \"%s\"",
                  client,
                  client->name,
                  npa_scheduled_client_state_name(request_ptr->state)));

  /* Save the request in the client structure */
  request_ptr->request_time = request_time;
  request_ptr->late_probability = late_probability;
  request_ptr->notification = notification;
  request_ptr->context = context;

  /* Swap out issue_request() function pointer with
   * scheduled_issue_request() but save original
   * for scheduler to call.
   */
  request_ptr->issue_request = client->issue_request;
  client->issue_request = npa_issue_scheduled_request;

  /* state is waiting for on "issue_request" call to happen */
  request_ptr->state = NPA_SCHEDULED_CLIENT_EXPECTING;

  /* notification state is that nothing for this request has ran yet.
   */
  request_ptr->notify_state = NPA_SCHEDULED_NOTIFICATION_NO_ACTION;

  return (client);
}


/**
 * <!-- npa_scheduler_init_task -->
 *
 * @brief Start up the NPA Scheduler tsk
 * 
 * To be ran at initialization time.  Will Core Fatal if the task
 * could not be started.
 *
 * @param config_data - Pointer to scheduler configuration data
 */
void npa_scheduler_init_task(const npa_scheduler_config *config_data)
{
  int i;
   /* create events to send to this task */
  for (i=0; i < NPA_SCHEDULED_ACTION_UNDEFINED; ++i)
  {
    CORE_DAL_VERIFY( 
      DALSYS_EventCreate( DALSYS_EVENT_ATTR_CLIENT_DEFAULT, 
                          &npa_scheduler.events_array[i],
                          NULL ) );
    CORE_DAL_VERIFY( 
      DALSYS_EventCtrl( npa_scheduler.events_array[i], 
                        DALSYS_EVENT_CTRL_RESET ) );
  }
}


/**
 * <!-- npa_schedule_timeout_callback -->
 *
 * @brief Handles Timer Callbacks
 * 
 * Triggers the Scheduler workloop with an action to process the 
 * schedule requests from the timer thread.
 *
 * @param data : Data passed by timer.  Defined when calling timer_def().
 */
void npa_scheduler_timeout_callback(timer_cb_data_type data)
{
  uint64 cur_time;
  int64 delta_time;

  if (npa_scheduler.sleep.enter)
  {
    CORE_LOG_VERIFY(0,
        ULOG_RT_PRINTF_0( npa.log, 
                          "ERROR npa_scheduler_timeout_callback"
                          " - not callable in sleep lpr enter function"
                          " - npa_scheduler.sleep.enter != 0")
                        );
  }

  cur_time = npa_scheduler.timer.timedout_at = CoreTimetick_Get64();

  /* Measure desired timeout vs current */
  delta_time = npa_compare_times(npa_scheduler.timer.current_timeout, 
                                 cur_time);
  if (delta_time < 0)
  { /* Callback is late */
      npa_calc_duration(npa_scheduler.timer.current_timeout,
                        cur_time,
                        &npa_scheduler.stats.timeout_callback_late);
  }
  else
  { /* ontime*/
    npa_calc_duration(cur_time,
                      npa_scheduler.timer.current_timeout,
                      &npa_scheduler.stats.timeout_callback_early);
  }

  npa_scheduler_signal_task( NPA_SCHEDULED_ACTION_TIMEOUT );
}

/*======================================================================
  Public Functions
  ======================================================================*/
/** Updated npa configuration data */
npa_scheduler_config npa_scheduler_live_config;


/**
 * <!-- npa_init_scheduler -->
 * 
 * @brief Init scheduled request data structures, but not timer 
 */
void npa_init_scheduler(void)
{
  ULogResult ulog_result;
  const npa_scheduler_config *config_data = npa_scheduler_target_config();

  if (npa_scheduler_exists)
  { /* already initialized */
    return;
  }

  npa_scheduler_exists = 2;

  /* Need a way to tell the linker to use this variable as
   * some will remove it if not used.
   */
  ULOG_RT_PRINTF_1( npa_scheduler.log,
                    "(npa_sleep_lpr_supported: %d)",
                    npa_sleep_lpr_supported);

  ulog_result = ULogFront_RealTimeInit(&npa_scheduler.log,
                                       NPA_SCHEDULER_DEFAULT_LOG_NAME,
                                       config_data->log_buffer_size,
                                       ULOG_MEMORY_LOCAL,
                                       ULOG_LOCK_OS );

  /* Log created succefully, or it is incomplete and the buffer size is zero
   * are valid non-error values.
   */
  CORE_VERIFY(DAL_SUCCESS == ulog_result
              || (ULOG_ERR_INITINCOMPLETE == ulog_result
                  && 0 == config_data->log_buffer_size));

  ULOG_RT_PRINTF_1( npa_scheduler.log, "npa_init_scheduler (config_data: 0x%08x)",
                    config_data );

  if (0 == config_data->scheduled_request_workloop.num_events)
  { /* no events allowed so feature is disabled */
    return;
  }
  /* else we should init scheduled requests */

  /* record config info */
  npa_scheduler.config_ptr = config_data;

  /* create locks for accessing npa_scheduler queues */
  CORE_VERIFY_PTR( 
    npa_scheduler.request_queue.lock 
      = Core_MutexCreate(CORE_MUTEXATTR_DEFAULT));

  /* Fork queue does not need to be sorted as it is always
   * cleared at one time and it is filled off of a already
   * sorted list
   */
  CORE_VERIFY_PTR( 
    npa_scheduler.forked_queue.lock 
      = Core_MutexCreate(CORE_MUTEXATTR_DEFAULT));
  npa_scheduler.forked_queue.not_sorted = 1;

  CORE_VERIFY_PTR( 
    npa_scheduler.complete_queue.lock 
      = Core_MutexCreate(CORE_MUTEXATTR_DEFAULT));

  /* create scheduler thread lock */
  CORE_VERIFY_PTR( 
    npa_scheduler.scheduler_work_lock 
      = Core_MutexCreate(CORE_MUTEXATTR_DEFAULT));

  /* Create request data pool */
  npa_init_pool( &npa_scheduler.data_pool,
                 &config_data->scheduled_request_allocation,
                 sizeof(npa_scheduler_data) );

  /* initialize data structures of the NPA Scheduler thread */
  npa_scheduler_init_task(config_data);

  /* create a client to the rpm polling mode resource when it is available */
  npa_resource_available_cb( "/protocol/rpm/polling_mode",
                             npa_scheduler_create_rpm_polling_mode_client,
                             NULL );

  /* need to wait until /init/timer is available before
   * the scheduler can setup the timer.
   */
  npa_resource_available_cb( "/init/timer",
                             npa_init_scheduler_timer_callback,
                             NULL );

  /* need to wait until /clk/cpu is available before
   * the scheduler can create the client.
   */
  npa_resource_available_cb( "/clk/cpu",
                             npa_init_scheduler_clk_cpu_callback,
                             NULL );

  /* Need /core/cpu/busy for Implied Complete processing */
  npa_resource_available_cb( "/core/cpu/busy",
                             npa_init_scheduler_core_cpu_busy_callback,
                             NULL );

  npa_scheduler_lpr_issuable_config();

  /* parse the resource latency override information and put it into
   * a list to be parsed at client creation to determine default latencies.
   */
  npa_resource_overrides_config(&npa_scheduler.overrides_list);

  /* let world know that Scheduled Request is up */
  npa_define_marker("/init/npa_scheduled_requests");
}


/**
 * <!-- npa_create_schedulable_client_ex -->
 *
 *
 */
npa_client_handle npa_create_schedulable_client_ex(const char *resource_name,
                                                   const char *client_name,
                                                   npa_client_type client_type,
                                                   unsigned int client_value,
                                                   void *client_ref)
{
  npa_client    *client;
  npa_scheduler_data *request_ptr;
  uint32 req_time, fork_time, notify_time;
  npa_resource_latency_data *internal_data_ptr;

  if (0 == npa_scheduler_exists)
  {  /* if no workloop, then feature not enabled so
      * say that the client could not be created
      */
     ULOG_RT_PRINTF_3( npa.log,
                "FAILED npa_create_scheduleable_client (resource: \"%s\") "
                "(client: \"%s\") (client_type: \"%s\"):"
                "NPA target configuration does not support scheduled clients",
                resource_name,
                client_name,
                npa_client_type_name(client_type) );
    return (NULL);
  }

  ULOG_RT_PRINTF_3( npa.log,
                    "npa_create_scheduable_client_ex "
                    "(resource: \"%s\") (client: \"%s\") (type: \"%s\")",
                    resource_name, client_name,
                    npa_client_type_name( client_type ) );

  /* try to create a new client */
  client = npa_create_sync_client_ex(resource_name,
                                     client_name, 
                                     client_type,
                                     client_value,
                                     client_ref);

  if (NULL != client)
  { /* create schedule request data structure */
    
    /* Klocworks */
    CORE_VERIFY_PTR(client->resource);
    CORE_VERIFY_PTR(client->resource->_internal);

    CORE_VERIFY_PTR(request_ptr = Core_PoolAlloc( &npa_scheduler.data_pool ));

    memset(request_ptr,0,sizeof(npa_scheduler_data));
    
    client->request_ptr = request_ptr;

    /* set default latency */
    req_time = npa_scheduler.config_ptr->request_latency;
    fork_time = npa_scheduler.config_ptr->fork_latency;
    notify_time = npa_scheduler.config_ptr->notify_latency;

    /* Check to see if there is any resource specific latency values */
    internal_data_ptr 
        = npa_get_resource_override_latency(&npa_scheduler.overrides_list,
                                            resource_name);
    if (internal_data_ptr)
    { /* non-NULL means resource has override data */
      /* see if it overrides default */
      if (internal_data_ptr->req_latency != 0xffffffff)
      { /* valid request time */
        req_time = internal_data_ptr->req_latency;
      }
      if (internal_data_ptr->fork_latency != 0xffffffff)
      { /* valid fork time */
        fork_time = internal_data_ptr->fork_latency;
      }
      if (internal_data_ptr->notify_latency != 0xffffffff)
      {/* valid latency time */
        notify_time = internal_data_ptr->notify_latency;
      }
    }

    /* set the desired default value */
    request_ptr->default_latency.request = req_time;
    request_ptr->default_latency.fork = fork_time;
    request_ptr->default_latency.notify = notify_time;
  }

  return(client);
}


/**
 * <!-- npa_destroy_schedulable_client -->
 *
 */
void npa_destroy_schedulable_client(npa_client_handle client)
{
  npa_scheduler_data *request_ptr;

  if (NULL == client->request_ptr)
  { /* not schedulable so just ignore the call then */
    return;
  }
  
  /* close race condition with scheduler */
  Core_MutexLock(npa_scheduler.scheduler_work_lock);
  
  request_ptr = client->request_ptr;

  /* client may have a request pending so remove it.
   * If the request is in progress, this will then block
   * until it is done.
   */
  npa_unschedule_request(client);

  client->request_ptr = NULL; /* no dangling pointers */

  /* ok now to remove memory */
  Core_MutexUnlock(npa_scheduler.scheduler_work_lock);

  /* remove memory */
  Core_PoolFree( &npa_scheduler.data_pool, request_ptr );
  /* request_ptr = NULL; Uncomment if ever put more code below this */
}


/**
 * <!-- npa_schedule_client_qclk -->
 *
 * @brief Places client into scheduled request mode.
 *
 * Creates a scheduled request that the system will attempt to honor
 * and complete by the requested deadline time in QTimer ticks.
 *
 * The deadline is the time the scheduled request should be completed by.
 *
 * The notification callback is required (cannot be null) and will be invoked
 * when the request is complete. Note that the callback will be ran in the
 * Schedule Request scheduler thread.
 * This client cannot be reused until either the notification callback is 
 * invoked or npa_unschedule_request is invoked and the client is successfully
 * moved out of Scheduled mode.
 *
 * It is expected that not all scheduled requests are of equal importance.
 * Late probability is the percentage of time (in 2^-31) that a late completion
 * can be tolerated.  0 (no lateness is acceptable) can be passed.
 * The scheduler will use this in determining how worst-case of latency should
 * be accounted for. Even with a value of zero, it is not possible to guarantee
 * completion by the given deadline, but the scheduler will make a best effort
 * to complete the request by the given time.
 *
 * @param client : Handle of the client for the request.  Client handles are
 * the same as the address of the npa_client structure.
 * @param request_time : Target absolute time for the request to be fininshed.
 * Units are T_TICKS for QTimer.
 * @param late_probablity : Percentage of time (in 2^-31) that a late 
 * completion can be tolerated. 0 lateness is acceptable.
 * @param notification : Callback function to be called by scheduler when
 * request is completed. This may occur in a differnt thread.
 * @param context : data to be passed to call_back as parameters.
 *
 * @return Return value is the client handle passed in.
 */
npa_client_handle npa_schedule_client_qclk( npa_client_handle client, 
                                            uint64 request_time, 
                                            uint32 late_probability,
                                            npa_scheduler_callback notification,
                                            void * context )
{
  /* Make sure this is a schedulable client */
  CORE_VERIFY_PTR(client);
  CORE_VERIFY_PTR(client->request_ptr);

  ULOG_RT_PRINTF_7( npa.log,
                    "npa_schedule_client "
                    "(handle: 0x%08x) (client: \"%s\") "
                    "(time: 0x%016llx) (late_prob: %d)"
                    "(notification: 0x%08x) (context: 0x%x) ",
                    client, client->name, 
                    ULOG64_LOWWORD(request_time),
                    ULOG64_HIGHWORD(request_time),
                    late_probability,
                    notification, context );

  /* schedule the client */
  return(npa_schedule_client_internal( client,
                                       request_time,
                                       late_probability,
                                       notification,
                                       context));
}


/**
 * <!-- npa_release_and_schedule_client_qclk -->
 *
 * @brief Places client into scheduled request mode and completes any current
 * request on the client.
 *
 * Creates a scheduled request that the system will attempt to honor
 * and complete by the requested deadline time.  It will also complete
 * an current requests in the most determined optimal method.  This can be
 * either issueing the "npa_complete()" immediately to just waiting for the
 * system to go to sleep and letting the Next Active Set and Sleep set handle
 * the cancel.
 *
 * The deadline is the time the scheduled request should be completed by.
 *
 * The notification callback is required (cannot be null) and will be invoked
 * when the request is complete. Note that the callback will be ran in the
 * Schedule Request scheduler thread.
 * This client cannot be reused until either the notification callback is
 * invoked or npa_unschedule_request is invoked and the client is successfully
 * moved out of Scheduled mode.
 *
 * It is expected that not all scheduled requests are of equal importance.
 * Late probability is the percentage of time (in 2^-31) that a late completion
 * can be tolerated.  0 (no lateness is acceptable) can be passed.
 * The scheduler will use this in determining how worst-case of latency should
 * be accounted for. Even with a value of zero, it is not possible to guarantee
 * completion by the given deadline, but the scheduler will make a best effort
 * to complete the request by the given time.
 *
 * @param client : Handle of the client for the request. Client handles are
 * the same as the address of the npa_client structure.
 * @param deadline_time : Target absolute time for the request to be fininshed.
 * Units are T_TICKS for qclock.
 * @param late_probablity : percentage of time (in 2^-31) that a late 
 * completion can be tolerated. 0 lateness is acceptable.
 * @param notification : Callback function to be called by scheduler when
 * request is completed. This may occur in a differnt thread.
 * @param context : data to be passed to call_back as parameters.
 *
 * @return Return value is the client handle passed in.
 */
npa_client_handle 
    npa_release_and_schedule_client_qclk( npa_client_handle client, 
                                          uint64 request_time, 
                                          uint32 late_probability,
                                          npa_scheduler_callback notification,
                                          void * context )
{
  /* Make sure this is a schedulable client */
  CORE_VERIFY_PTR(client);
  CORE_VERIFY_PTR(client->request_ptr);

  ULOG_RT_PRINTF_7( npa.log,
                    "npa_release_and_schedule_client_qtime "
                    "(handle: 0x%08x) (client: \"%s\") "
                    "(time: 0x%016llx) (late_prob: %d)"
                    "(notification: 0x%08x) (context: 0x%x) ",
                    client,
                    client->name, 
                    ULOG64_LOWWORD(request_time),
                    ULOG64_HIGHWORD(request_time),
                    late_probability,
                    notification,
                    context );

  /* Mark that there is a release and schedule in progress */
  client->request_ptr->implied_state = NPA_IMPLIED_COMPLETE_PENDING;

  /* schedule the client */
  return(npa_schedule_client_internal( client,
                                       request_time,
                                       late_probability,
                                       notification,
                                       context));
}


/**
 * <!-- npa_unschedule_request -->
 *
 * @brief Remove client from scheduled request mode.
 *
 * Takes a client and if it is in Scheduled Resource mode, moves it back
 * into normal operation mode (i.e. no scheduled).
 *
 * The notification callback setup by npa_schedule_client may still be invoked
 * by the scheduler thread if the request is currently being processed.
 *
 * This function is safe to call even if the client does not currently have an
 * active request scheduled against it but will error if it is not a 
 * schedulable client.
 *
 * @note If the scheduled request was started with a call to
 * npa_release_and_schedule_client(), the request has not been handled
 * by the NPA Scheduler and the implied complete has  not happened,
 * the implied complete will be issued in the caller's thread before
 * returning from this function.  This is to force the client request
 * into a known state - either the complete or the request has been
 * handled. 
 *
 * @param client : Handle of the client for the request. Client handles are
 * the same as the address of the npa_client structure.
 *
 * @return Return value is the notification state of this request.
 */
npa_scheduled_notification_state 
    npa_unschedule_request(npa_client_handle client)
{
  npa_scheduler_data *request_ptr;
  uint64 start_time;

  /* assume that the request has not started so will be cleanly unscheduled */
  npa_scheduled_notification_state 
    notify_state = NPA_SCHEDULED_NOTIFICATION_UNSCHEDULED;

  /* time for measuring duration */
  start_time = CoreTimetick_Get64();

  /* Verify that inputs are valid */
  CORE_VERIFY_PTR(client);

  request_ptr = client->request_ptr;

  if (NULL == request_ptr)
  { /* not a scheduable client so ignore the call */

    ULOG_RT_PRINTF_2( npa.log, 
                      "npa_unschedule_request"
                      "(handle:0x%08x)"
                      " (client: \"%s\")"
                      " Not a schedulable client",
                      client,
                      client->name);
    return(notify_state);
  }
  
  ULOG_RT_PRINTF_4( npa.log, "npa_unschedule_request"
                    " (handle:0x%08x)"
                    " (client: \"%s\")"
                    " (state: %d - \"%s\")",
                    client, 
                    client->name,
                    request_ptr->state,
                    npa_scheduled_client_state_name(request_ptr->state));

  /* Lock the scheduler work loop.
   * Note that if the request is being processed, then
   * this lock will block until it is completed.
   */
  Core_MutexLock(npa_scheduler.scheduler_work_lock);

  ULOG_RT_PRINTF_4( npa_scheduler.log, 
                    "  npa_unschedule_request Locked"
                    " (handle:0x%08x)"
                    " (client: \"%s\")"
                    " (state: %d - \"%s\")",
                    client, 
                    client->name,
                    request_ptr->state,
                    npa_scheduled_client_state_name(request_ptr->state));

  switch (request_ptr->state)
  {

    case NPA_SCHEDULED_CLIENT_INACTIVE:
      /* Nothing to do. */
      notify_state = request_ptr->notify_state;
      /* told someone about it so state needs cleaned up */
      request_ptr->notify_state = NPA_SCHEDULED_NOTIFICATION_NO_ACTION;
      break;

    case NPA_SCHEDULED_CLIENT_LINKED:
      /* client still in link list so we can remove it */
      npa_scheduler_remove(client,
                           NPA_UPDATE_START_TIMES,
                           NPA_LOCK_LIST);

      ULOG_RT_PRINTF_3( npa_scheduler.log, 
                        "  npa_unschedule_request Removed from List"
                        " (handle:0x%08x)"
                        " (client: \"%s\")"
                        " (state: \"%s\")",
                        client, 
                        client->name,
                        npa_scheduled_client_state_name(request_ptr->state));
    /* Fall into NPA_SCHEDULED_CLIENT_EXPECTING state */

    case NPA_SCHEDULED_CLIENT_UNLINKED: /* may have hit the window in scheduler
                                         * task where it was removed from the
                                         * queue but preempted before locking
                                         * so not processed yet.
                                         */
      /* If an implied complete is expected, then complete the previous 
       * request so the client is in a known state.  We are protected
       * by the scheduler lock up above.  Don't do this for EXPECTING
       * as no issue_request has occured yet so the handshake is not
       * complete.
       */
      if (NPA_IMPLIED_COMPLETE_PENDING == request_ptr->implied_state)
      { /* Complete is expected */
        /* Remove from the implied complete list */
        npa_list_Remove(&npa_scheduler.implied_completes_now_list, client);
        npa_issue_implied_complete(client);
      }
      if (NPA_IMPLIED_COMPLETE_EXECUTED == request_ptr->implied_state)
      { /* somthing happened so update state */
        notify_state = NPA_SCHEDULED_NOTIFICATION_IMPLIED_COMPLETE_ISSUED;
      }
      
    /* Fall into NPA_SCHEDULED_CLIENT_EXPECTING state */

    case NPA_SCHEDULED_CLIENT_EXPECTING:
      /* No issue request has happened yet so backout the scheduled request */
      /* restore original issue request */
      client->issue_request = request_ptr->issue_request;
      /* No implied complete */
      request_ptr->implied_state = NPA_NO_IMPLIED_COMPLETE;
      request_ptr->issue_request = NULL; /* no dangling pointers */

      /* Request is no longer active */
      request_ptr->state = NPA_SCHEDULED_CLIENT_INACTIVE;
      break;

    case NPA_SCHEDULED_CLIENT_NOTIFY_EXPECTED:
      /* Client has done the fork and waiting for a notify.
       * Needs to finish up the notify before request
       * is unscheduled.
       */
      ULOG_RT_PRINTF_2( npa_scheduler.log, 
                        "  npa_unschedule_request Force Notify"
                        " (handle:0x%08x)"
                        " (client: \"%s\")",
                        client,
                        client->name);

      ++npa_scheduler.stats.forced_notifies;

      /* run all notifies since they are just waiting to do notificaitons */
      npa_run_scheduler_notifies();

      ULOG_RT_PRINTF_3( npa_scheduler.log, 
                        "  npa_unschedule_request Notified"
                        " (handle:0x%08x)"
                        " (client: \"%s\")"
                        " (state: \"%s\")",
                        client, 
                        client->name,
                        npa_scheduled_client_state_name(request_ptr->state));

      /* somthing happened so update state */
      notify_state = request_ptr->notify_state;

      /* request is now finished and in correct state */
      break;

    case NPA_SCHEDULED_CLIENT_IN_PROGRESS:
    case NPA_SCHEDULED_CLIENT_FORKING:
    case NPA_SCHEDULED_CLIENT_UNDEFINED:
    default:
      /* shouldn't be in this state when requests can be unscheduling. */
      CORE_LOG_VERIFY(0,
                      ULOG_RT_PRINTF_3( 
                        npa.log, 
                        "ERROR npa_unschedule_request (handle:0x%08x) "
                        "(client: \"%s\") "
                        "Can't unschedule while in state \"%s\")",
                        client, 
                        client->name,
                        npa_scheduled_client_state_name(request_ptr->state)));
      break;
  }

  /* the "last" request is now being reported when this function returns,
   *  so any other unschedules will not do any work until something else
   * is scheduled.
   */
  request_ptr->notify_state = NPA_SCHEDULED_NOTIFICATION_NO_ACTION;

  /* Setup timer that may have changed */
  npa_setup_next_timeout();

  Core_MutexUnlock(npa_scheduler.scheduler_work_lock);

  ULOG_RT_PRINTF_6( npa_scheduler.log, 
                    "  DONE npa_unschedule_request"
                    " (handle:0x%08x)"
                    " (client: \"%s\")"
                    " (state: %d - \"%s\")"
                    " (notify_state: \"%s\")"
                    " (dur: %d ticks)",
                    client, 
                    client->name,
                    request_ptr->state,
                    npa_scheduled_client_state_name(request_ptr->state),
                    npa_scheduler_status_name(notify_state),
                    (int32) npa_compare_times(CoreTimetick_Get64(), 
                                              start_time));

  return (notify_state);
}


/**
 * <!-- npa_sync_scheduled_request -->
 *
 * @brief Force immediate exection of any pending scheduled request on a client
 *
 * Takes a client and if it is in Scheduled Resource mode with a pending
 * issued request, forces it to execute immediately, else it will remove any
 * client waiting for the issue. 
 *
 * The notification callback setup by npa_schedule_client will be invoked
 * if the scheduled issued request is pending or currently being processed.
 *
 * This function is safe to call even if the client does not currently have an
 * active request scheduled against it but will error if it is not a 
 * schedulable client.
 *
 * @param client : Handle of the client for the request. Client handles are
 * the same as the address of the npa_client structure.
 *
 * @return Return value is the notification state of this request.  Return
 * NPA_SCHEDULED_NOTIFICAITON_NO_ACTION if there was no issued request pending.
 * Else will return NPA_SCHEDULED_NOTIFICATION_LATE
 */
npa_scheduled_notification_state 
     npa_sync_scheduled_request(npa_client_handle client)
{
  npa_scheduler_data *request_ptr;
  uint64 start_time;

  /* Assume no action state */
  npa_scheduled_notification_state 
    notify_state = NPA_SCHEDULED_NOTIFICATION_NO_ACTION;

  /* time for measuring duration */
  start_time = CoreTimetick_Get64();

  /* Verify that inputs are valid */
  CORE_VERIFY_PTR(client);

  request_ptr = client->request_ptr;

  if (NULL == request_ptr)
  { /* not a scheduable client so ignore the call */

    ULOG_RT_PRINTF_2( npa.log, 
                      "npa_sync_scheduled_request"
                      "(handle:0x%08x)"
                      " (client: \"%s\")"
                      " Not a schedulable client",
                      client,
                      client->name);
    return(notify_state);
  }
  
  ULOG_RT_PRINTF_4( npa.log, "npa_sync_scheduled_request"
                    " (handle:0x%08x)"
                    " (client: \"%s\")"
                    " (state: %d - \"%s\")",
                    client, 
                    client->name,
                    request_ptr->state,
                    npa_scheduled_client_state_name(request_ptr->state));

  /* Lock the scheduler work loop.
   * Note that if the request is being processed, then
   * this lock will block until it is completed.
   */
  Core_MutexLock(npa_scheduler.scheduler_work_lock);

  ULOG_RT_PRINTF_4( npa_scheduler.log, 
                    "  npa_sync_scheduled_request Locked"
                    " (handle:0x%08x)"
                    " (client: \"%s\")"
                    " (state: %d - \"%s\")",
                    client, 
                    client->name,
                    request_ptr->state,
                    npa_scheduled_client_state_name(request_ptr->state));

  switch (request_ptr->state)
  {

    case NPA_SCHEDULED_CLIENT_INACTIVE:
      /* Nothing to do. */
      break;

    case NPA_SCHEDULED_CLIENT_EXPECTING:
      /* scheduled but no issue_request has happened */
      /* so restore original issue request */
      client->issue_request = request_ptr->issue_request;
      request_ptr->issue_request = NULL; /* no dangling pointers */

      /* Request is no longer active */
      request_ptr->state = NPA_SCHEDULED_CLIENT_INACTIVE;

      notify_state = request_ptr->notify_state;
      break;

    case NPA_SCHEDULED_CLIENT_LINKED:
      /* Request pending and client still in link list so we can remove it */
      npa_scheduler_remove(client,
                           NPA_UPDATE_START_TIMES,
                           NPA_LOCK_LIST);

      ULOG_RT_PRINTF_3( npa_scheduler.log, 
                        "  npa_sync_scheduled_request Removed from List"
                        " (handle:0x%08x)"
                        " (client: \"%s\")"
                        " (state: \"%s\")",
                        client, 
                        client->name,
                        npa_scheduled_client_state_name(request_ptr->state));
    /* Fall into NPA_SCHEDULED_CLIENT_UNLINKED state */

    case NPA_SCHEDULED_CLIENT_UNLINKED: 
      /* may have hit the window in scheduler task where it was 
       * removed from the queue but preempted before locking
       * so not processed yet.
       */
      /* Run the request */
      ++npa_scheduler.stats.sched_requests_handled;

      /* run the request.
       * this call will clear out request_ptr->notification.
       */
      npa_run_scheduler_request(client,
                                &client->request_ptr->stats.full_issue_request_duration);

      /* issue notification inside the lock.
       */
      npa_scheduler_notify(client, NULL);

      /* something happened so update state */
      notify_state = request_ptr->notify_state;

      break;

    case NPA_SCHEDULED_CLIENT_NOTIFY_EXPECTED:
      /* Client has done the fork and waiting for a notifies.
       * Needs to finish up the notifies.
       */
      ULOG_RT_PRINTF_2( npa_scheduler.log, 
                        "  npa_sync_scheduled_request Notify"
                        " (handle:0x%08x)"
                        " (client: \"%s\")",
                        client,
                        client->name);

      /* run all notifies since they are just waiting to do notificaitons */
      npa_run_scheduler_notifies();

      /* somthing happened so update state */
      notify_state = request_ptr->notify_state;

      /* All notify request are now finished and in correct state */
      break;

    case NPA_SCHEDULED_CLIENT_IN_PROGRESS:
    case NPA_SCHEDULED_CLIENT_FORKING:
    case NPA_SCHEDULED_CLIENT_UNDEFINED:
    default:
      /* shouldn't be in this state when requests can be unscheduling. */
      CORE_LOG_VERIFY(0,
                      ULOG_RT_PRINTF_3( 
                        npa.log, 
                        "ERROR npa_sync_scheduled_request (handle:0x%08x) "
                        "(client: \"%s\") "
                        "Can't unschedule while in state \"%s\")",
                        client, 
                        client->name,
                        npa_scheduled_client_state_name(request_ptr->state)));
      break;
  }

  
  /* Setup timer that may have changed */
  npa_setup_next_timeout();

  Core_MutexUnlock(npa_scheduler.scheduler_work_lock);

  ULOG_RT_PRINTF_6( npa_scheduler.log, 
                    "  DONE npa_sync_scheduled_request"
                    " (handle:0x%08x)"
                    " (client: \"%s\")"
                    " (state: %d - \"%s\")"
                    " (notify_state: \"%s\")"
                    " (dur: %d ticks)",
                    client, 
                    client->name,
                    request_ptr->state,
                    npa_scheduled_client_state_name(request_ptr->state),
                    npa_scheduler_status_name(notify_state),
                    (int32) npa_compare_times(CoreTimetick_Get64(), 
                                              start_time));

  return (notify_state);
}


/**
 * <!-- npa_scheduler_status_name -->
 * 
 * @brief Status to a string request
 *
 * Returns a pointer to a constant string of the text for the
 * npa_scheduled_notification_state.
 *  
 * @param state : npa_scheduled_notification_state value
 * @param state : requested resource state
 *
 * @return Returns string ptr of the name.
 */
const char *npa_scheduler_status_name(
                   npa_scheduled_notification_state state)
{
  switch(state)
  {
    case NPA_SCHEDULED_NOTIFICATION_LATE:
      return("NPA_SCHEDULED_NOTIFICATION_LATE");

    case NPA_SCHEDULED_NOTIFICATION_ON_TIME:
      return("NPA_SCHEDULED_NOTIFICATION_ON_TIME");

    case NPA_SCHEDULED_NOTIFICATION_UNSCHEDULED:
      return("NPA_SCHEDULED_NOTIFICATION_UNSCHEDULED");

    case NPA_SCHEDULED_NOTIFICATION_NO_ACTION:
      return("NPA_SCHEDULED_NOTIFICATION_NO_ACTION");

    default:
      return("Unknown npa_scheduled_notification_state");
  }
}


/**
 * <!-- npa_scheduler_client_state_name -->
 *
 * @brief status to a string request
 *
 * Returns a pointer to a constant string of the text for the
 * npa_scheduled_notification_state.
 *
 * @param state: npa_scheduled_client_state value
 *
 * @return string ptr of the name.
 */
const char *npa_scheduled_client_state_name(npa_scheduled_client_state state)
{
  switch(state)
  {
    case NPA_SCHEDULED_CLIENT_INACTIVE:
      return "NPA_SCHEDULED_CLIENT_INACTIVE";
    
    case NPA_SCHEDULED_CLIENT_EXPECTING:
      return "NPA_SCHEDULED_CLIENT_EXPECTING";
    
    case NPA_SCHEDULED_CLIENT_LINKED:
      return "NPA_SCHEDULED_CLIENT_LINKED";
    
    case NPA_SCHEDULED_CLIENT_UNLINKED:
      return "NPA_SCHEDULED_CLIENT_UNLINKED";
    
    case NPA_SCHEDULED_CLIENT_FORKING:
      return "NPA_SCHEDULED_CLIENT_FORKING";
      
    case NPA_SCHEDULED_CLIENT_NOTIFY_EXPECTED:
      return "NPA_SCHEDULED_CLIENT_NOTIFY_EXPECTED";
    
    case NPA_SCHEDULED_CLIENT_IN_PROGRESS:
      return "NPA_SCHEDULED_CLIENT_IN_PROGRESS";
    
    case NPA_SCHEDULED_CLIENT_UNDEFINED:
      return "NPA_SCHEDULED_CLIENT_UNDEFINED";

    default:
      return "Unknown npa_scheduled_client_state";
  }
}


/**
 * <!-- npa_scheduler_clear_client_stats -->
 * 
 * @brief Clears a clients statistics area.
 *
 * @param client : Client handle for the clear
 */
void npa_scheduler_clear_client_stats(npa_client_handle client)
{
  memset(&client->request_ptr->stats,0,sizeof(client->request_ptr->stats));
}


/**
 * <!-- npa_scheduler_clear_control_stats-->
 * 
 * @brief Clears the request scheduler's statistics area.
 */
void npa_scheduler_clear_control_stats(void)
{
  memset(&npa_scheduler.stats,0,sizeof(npa_scheduler.stats));
}


/**
 * <!-- npa_scheduler_calc_lpr_entry_lat --> 
 *
 * @brief  Calculates the time the LPR will spend for the next timeout if Sleep is entered.
 *
 * This is the summing of the forked time of all the requests that would fire
 * in the next timeout.
 * 
 * WARNING - Must be called in a thread safe environment or with the request
 * queue locked.
 * 
 * @param coeffs : Coefficients for the latency equation. In case of polynomial
 * coeffs[0] + coeffs[1]*x_value + coeffs[2]*x_value^2 + ... + coeffs[n]*x_value^n. (Not used)
 * @param x_value: Variable part for the latency equation. (Not Used)
 *
 * @return time required in sclk to enter a low power mode.
 */
uint32 npa_scheduler_calc_lpr_entry_lat(sleep_coeffs *coeffs,
                                        uint32 x_value)
{
  uint64 max_handle_time;
  uint32 sum_time = npa_scheduler.config_ptr->lpr_enter_latency;
  npa_client_handle client;

  if (NULL == npa_scheduler.request_queue.head
      || NULL == npa_scheduler.request_queue.head->request_ptr) /* Klocworks */
  { /* list empty so nothing to do */
      return(sum_time);
  }

  /* end time for finding tasks is first item in
   * queue's requested end time
   * plus minimum reshechedule time.
   */
  max_handle_time = npa_scheduler.request_queue.head->request_ptr->request_time
                    + npa_scheduler.config_ptr->min_reschedule_delta;

  for (client = npa_scheduler.request_queue.head;
       (NULL != client)
       && (max_handle_time > client->request_ptr->start_time);
       client = client->request_ptr->next)
  { /* for all clients until past needed start time */
    if (npa_resource_has_attribute(client->resource, NPA_RESOURCE_LPR_ISSUABLE)
        && client->request_ptr->new_request)
    { /* can be issued in LPR and not short circuit */
      sum_time += client->request_ptr->active_latency.fork;
    }
  }
//  ULOG_RT_PRINTF_1( npa_scheduler.log,
//                    "npa_scheduler_calc_lpr_entry_lat (entry_lat:%d)",
//                    sum_time);
  return(sum_time);
}


/**
 * <!-- npa_scheduler_calc_lpr_exit_lat --> 
 *
 * @brief Calculates the time the LPR will spend for the next timeout if Sleep
 * is entered.
 *
 * This is the summing of the notify time of all the requests that would fire
 * in the next timeout.
 *
 * WARNING - Must be called in a thread safe environment or with the request
 * queue locked.
 *
 * @param coeffs: Coefficients for the latency equation. In case of polynomial
 * coeffs[0] + coeffs[1]*x_value + coeffs[2]*x_value^2 + ... + coeffs[n]*x_value^n. (Not used)
 * @param x_value: Variable part for the latency equation. (Not Used)
 * 
 * @return time required in sclk to exit a low power mode.
 */
uint32 npa_scheduler_calc_lpr_exit_lat(sleep_coeffs *coeffs,
                                       uint32 x_value)
{
/*  ULOG_RT_PRINTF_1( npa_scheduler.log,
                    "npa_scheduler_calc_lpr_exit_lat (exit_lat:%d)",
                    npa_scheduler.config_ptr->lpr_exit_latency);
*/
  return(npa_scheduler.config_ptr->lpr_exit_latency);
}


/**
 * <!-- npa_scheduler_walk_list -->
 * 
 * @brief Debug check for a valid scheduled client list. 
 *
 * Walks through the scheduled client lists to verify that
 * it is consistent.  It makes sure all are in the state
 * of NPA_SCHEDULED_CLIENT_LINKED and that the count 
 * matches the links in the list.
 *
 * This is a blocking routine on each list.
 *  
 * @return Returns number of detected errors in all lists.
 */
uint32 npa_scheduler_walk_list(void)
{
  npa_client_handle client = NULL;
  uint32 count = 0;
  uint32 error = 0;
  npa_scheduler_queue_struct *list_ptr;
  int i;
  /* do this for multiple queues */
  npa_scheduler_queue_struct *lists[] =
        { &npa_scheduler.request_queue,
          &npa_scheduler.forked_queue,
          &npa_scheduler.complete_queue,
          NULL
        };

  for (i = 0, list_ptr = lists[0];
       NULL != list_ptr;
       list_ptr = lists[++i], count = 0)
  {
    Core_MutexLock(list_ptr->lock);

    /* check that head and tail make sense */
    if ((NULL == list_ptr->head
         && NULL != list_ptr->tail)
         || (NULL != list_ptr->head
             && NULL == list_ptr->tail))
    { /* head and tail don't agree on list being empty or not */
      ULOG_RT_PRINTF_3( npa.log,
        "npa_scheduler_walk_list out of sync"
        " - head and tail not agree with eachother "
        "(list: 0x%08x)"
        "(head: 0x%08x)"
        "(tail: 0x%08x)",
        list_ptr,
        list_ptr->head,
        list_ptr->tail);
      ++error;
      /* cannot trust list so go to next list */
      Core_MutexUnlock(list_ptr->lock);
      continue;
    }

    for (client = list_ptr->head;
         client != NULL;
         client = client->request_ptr->next)
    { /* for each client in the list */

      if (++count > list_ptr->num_linked_clients)
      { /* have more elements than list says should have */
        ULOG_RT_PRINTF_2( npa.log,
                          "npa_scheduler_walk_list out of sync - counts off"
                          " (count:%d) (num_linked: %d)",
                          count, list_ptr->num_linked_clients);
        ++error;
        /* can't trust list so don't go any farther */
        break;
      }

      if (NULL == client->request_ptr)
      {/* all things in the list should have a request_ptr */
        ULOG_RT_PRINTF_1( npa.log,
          "npa_scheduler_walk_list out of sync - no requst_ptr"
          "(handle: 0x%08x)",
          client);
        ++error;
      }

      if (!(client->request_ptr->state == NPA_SCHEDULED_CLIENT_LINKED
            || client->request_ptr->state 
                 == NPA_SCHEDULED_CLIENT_NOTIFY_EXPECTED)
          )
      { /* client in the list so must be CLIENT_LINKED state and isn't */
        ULOG_RT_PRINTF_2( npa.log,
          "npa_scheduler_walk_list out of sync - client in wrong state"
          "(handle: 0x%08x) (state: \"%s\")",
          client, client->request_ptr->state);
        ++error;
      }

      if (!list_ptr->not_sorted && client->request_ptr->next)
      { /* sorted list and has a next so see if it is in order */
        if (client->request_ptr->request_time > client->request_ptr->next->request_ptr->request_time)
        { /* next's request time is before current's */
          ULOG_RT_PRINTF_7( npa.log,
            "npa_scheduler_walk_list out of sync - request_time out of time order "
            "(list: 0x%08x) "
            "(client: 0x%08x) "
            "(next: 0x%08x) "
            "(current's start: 0x%016llx) "
            "(next's start: 0x%016llx)",
            list_ptr,
            client,
            client->request_ptr->next,
            ULOG64_LOWWORD(client->request_ptr->request_time),
            ULOG64_HIGHWORD(client->request_ptr->request_time),
            ULOG64_LOWWORD(client->request_ptr->next->request_ptr->request_time),
            ULOG64_HIGHWORD(client->request_ptr->next->request_ptr->request_time));

          ++error;
        }
        if (client->request_ptr->start_time > client->request_ptr->next->request_ptr->start_time)
        { /* next's start time is before current's */
          ULOG_RT_PRINTF_7( npa.log,
            "npa_scheduler_walk_list out of sync - start_time out of time order "
            "(list: 0x%08x) "
            "(client: 0x%08x) "
            "(next: 0x%08x) "
            "(current's start: 0x%016llx) "
            "(next's start: 0x%016llx)",
            list_ptr,
            client,
            client->request_ptr->next,
            ULOG64_LOWWORD(client->request_ptr->start_time),
            ULOG64_HIGHWORD(client->request_ptr->start_time),
            ULOG64_LOWWORD(client->request_ptr->next->request_ptr->start_time),
            ULOG64_HIGHWORD(client->request_ptr->next->request_ptr->start_time));

          ++error;
        }
        if (client->request_ptr->start_time > client->request_ptr->request_time)
        { /* client's start time is after request time */
          ULOG_RT_PRINTF_7( npa.log,
            "npa_scheduler_walk_list out of sync - start_time > request_time "
            "(list: 0x%08x) "
            "(client: 0x%08x) "
            "(next: 0x%08x) "
            "(current's start: 0x%016llx) "
            "(current's request: 0x%016llx)",
            list_ptr,
            client,
            client->request_ptr->next,
            ULOG64_LOWWORD(client->request_ptr->start_time),
            ULOG64_HIGHWORD(client->request_ptr->start_time),
            ULOG64_LOWWORD(client->request_ptr->request_time),
            ULOG64_HIGHWORD(client->request_ptr->request_time));

          ++error;
        }
      }
    } /* for (client...) */

    if (count != list_ptr->num_linked_clients)
    {
      ULOG_RT_PRINTF_2( npa.log,
                       "npa_scheduler_walk_list out of sync - counts off"
                        " (count: %d) (num_linke_clients: %d)",
                        count, list_ptr->num_linked_clients);
      ++error;
    }

    Core_MutexUnlock(list_ptr->lock);
  } /* for (i...) */

  return(error);
}

/**
 * <!-- npaScheduler task -->
 *
 * @brief Wait on the npa_scheduler.events_array and process npa_scheduler_action_types
 *
 * @param unused_param: Parameter received from Main Control task - ignored
 */
void npaScheduler_task(unsigned long int unused_param)
{
  uint32 current_index;
  npa_scheduler_action action;

  /* Initialize the NPS Scheduler subsystem */
  npa_init_scheduler();

  /* Start the task */
  rcinit_handshake_startup();

  /* get thread id */
  npa_scheduler.thread_id = Core_ThreadSelf();

  /* Task processing */
  while( 1 )
  {
    /* Block until requests are complete */
    CORE_DAL_VERIFY( 
      DALSYS_EventMultipleWait(npa_scheduler.events_array, 
                               NPA_ARRAY_SIZE( npa_scheduler.events_array ),
                               DALSYS_EVENT_TIMEOUT_INFINITE,
                               &current_index));

    /* setup for common fields */
    action.type = (npa_scheduler_action_type)current_index;

    switch (current_index)
    {
  
      case NPA_SCHEDULER_ACTION_LPR_WAKEUP: /* LPR signaling task */      
        /* Make sure priority is now at highest value */
        /* Make sure priority is at desired value */
        Core_SetThreadPriority(npa_scheduler.thread_id,
                               npa_scheduler.config_ptr->scheduled_request_workloop.priority);
        /* Fall into next case */
      case NPA_SCHEDULED_ACTION_TIMEOUT:    /* Timeout event has occurred */
      case NPA_SCHEDULED_ACTION_TRIGGER:    /* Run the scheduled events */
        action.handler_fcn = npa_run_scheduler_requests;
        action.data = 0;
        action.handler_fcn(&action);
        break;

      case NPA_SCHEDULED_ACTION_IMPLIED_COMPLETE: /* Implied complete is needed */
        action.handler_fcn = npa_scheduler_handle_implied_complete;
        action.data = 0;
        action.handler_fcn(&action);
        break;

      default:
        /* ignore anything else valid but check that
         * valid range for sig is between 0 and UNDEFINED
         */
        CORE_LOG_VERIFY(NPA_SCHEDULED_ACTION_UNDEFINED > current_index,
                        ULOG_RT_PRINTF_1( npa_scheduler.log, 
                                          "ERROR npaScheduler_task"
                                          " current_index %d is out of range",
                                          current_index ));
        break;
    }
  }
}
